\chapter{Wstęp}

Postęp technologiczny w zakresie sztucznej inteligencji oraz \definicja{przetwarzania języka naturalnego} (\akronim{NLP}, \english{Natural Language Processing}) sprawia, że interakcja człowieka z komputerem staje się coraz bardziej intuicyjna. Jak zauważył Alan Turing już w 1950 roku \cite{turing1950}: „Maszyna może być uznana za inteligentną, jeśli jej odpowiedzi są nieodróżnialne od odpowiedzi człowieka”. Dziś wizja ta znajduje odzwierciedlenie w systemach zdolnych do interpretacji ludzkich wypowiedzi i podejmowania działań w oparciu o ich znaczenie.

Inspiracją do podjęcia niniejszego tematu była obserwacja potrzeb środowiska hodowców koni –- grupy zawodowej, która mimo dużego doświadczenia praktycznego często cechuje się niskim stopniem zinformatyzowania. Pomysł stworzenia aplikacji zrodził się z rozmowy z jednym z hodowców, wujkiem członka zespołu, który zwrócił uwagę na brak narzędzi umożliwiających wygodne zarządzanie stadniną. Zidentyfikowany problem oraz szybki rozwój technologii NLP doprowadziły do koncepcji stworzenia aplikacji sterowanej językiem naturalnym.

Celem projektu stało się opracowanie systemu webowego umożliwiającego zarządzanie stadniną koni oraz obsługę aplikacji poprzez komendy w języku naturalnym. Tego rodzaju rozwiązanie może istotnie obniżyć próg wejścia dla użytkowników nieposiadających kompetencji technicznych, a jednocześnie stanowić przykład praktycznego wykorzystania nowoczesnych modeli językowych w rzeczywistym środowisku.

Zakres pracy obejmuje analizę problemu, zaprojektowanie i implementację aplikacji webowej \definicja{Moje Konie}, stworzenie klasyfikatora intencji użytkownika, a także opracowanie metody automatycznego generowania zapytań REST na podstawie wypowiedzi naturalnych. Zakres czasowy pracy obejmował pełny cykl wytwarzania oprogramowania –- od analizy wymagań, poprzez implementację i integrację, aż po testy oraz ocenę skuteczności zastosowanych metod.

W pracy przyjęto hipotezę, że możliwe jest skuteczne sterowanie aplikacją webową poprzez wypowiedzi użytkownika w języku naturalnym, przy użyciu współczesnych modeli językowych, takich jak Gemini~2.5~Flash. Zakłada się również, że odpowiednio zaprojektowany klasyfikator intencji i moduł interpretacji poleceń umożliwią poprawne odwzorowanie wypowiedzi na konkretne żądania aplikacyjne.

Źródła literaturowe wykorzystane w pracy obejmują zarówno klasyczne opracowania z zakresu przetwarzania języka naturalnego, jak i najnowsze publikacje dotyczące dużych modeli językowych, architektury REST oraz projektowania aplikacji webowych. Ważnym odniesieniem stały się również dokumentacje narzędzi i bibliotek programistycznych wykorzystanych w projekcie, takich jak React, Node.js, PostgreSQL oraz Python.

Podczas realizacji projektu zespół napotkał na wyzwania związane z integracją komponentów aplikacji oraz dostosowaniem modeli NLP do specyficznej dziedziny, jaką jest hodowla koni. Kluczowe było także zapewnienie odpowiedniej komunikacji pomiędzy warstwą frontendową i serwerową, a także stworzenie środowiska umożliwiającego eksperymentalną ocenę skuteczności modeli.

Celem pracy jest opracowanie aplikacji webowej \definicja{Moje Konie} wykorzystującej przetwarzanie języka naturalnego do sterowania funkcjami systemu oraz analiza skuteczności zastosowanych metod klasyfikacji intencji i odwzorowywania wypowiedzi użytkownika na żądania REST.

	

	Struktura pracy jest następująca:
	\begin{description}
		\item[Rozdział~1] przedstawia przegląd literatury dotyczącej przetwarzania języka naturalnego oraz systemów interakcji człowiek–komputer.
		\item[Rozdział~2] opisuje projekt i implementację serwerowej części aplikacji do zarządzania stadniną koni.
		\item[Rozdział~3] zawiera opracowanie i ocenę eksperymentalną klasyfikatora intencji użytkownika.
		\item[Rozdział~4] opisuje metodę wypełniania żądań REST na podstawie wypowiedzi użytkownika przy użyciu dużego modelu językowego.
		\item[Rozdział~5] prezentuje integrację opracowanych modułów w aplikacji \definicja{Moje Konie}.
		\item[Rozdział~6] zawiera podsumowanie oraz wnioski z przeprowadzonej pracy.
	\end{description}

	

	Tomasz Pawłowski opracował architekturę systemu oraz był odpowiedzialny za implementację części serwerowej aplikacji. Jakub Buler pełnił funkcję głównego programisty, odpowiadając za implementację i integrację aplikacji webowej. Adam Detmer, jako kierownik projektu, zajmował się analizą biznesową, zarządzaniem zadaniami zespołu oraz opracowaniem klasyfikatora intencji użytkownika. Jakub Kamieniarz odpowiadał za przygotowanie modułu generowania żądań REST z wykorzystaniem modelu językowego Gemini~2.5~Flash.

	% TODO: Dobrze by było to powiązać z fragmentami pracy dyplomowej. Np. T.P. opracował architekturę systemu, opisaną w rozdziale 3.14 oraz był odpowiedzialny za implementację części serwerowej aplikacji, opisaną w rozdziale 2.72.
	
	% TODO: rozdzielić do osobnego pliku
	% TODO: poprawić wcięcia
	\chapter{Przetwarzanie języka naturalnego i klasyfikacja intencji}
	
	\section{Wprowadzenie do przetwarzania języka naturalnego}

	\definicja{Przetwarzanie języka naturalnego} (\akronim{NLP}, \english{Natural Language Processing}) jest dziedziną sztucznej inteligencji, której celem jest umożliwienie komputerom zrozumienia, analizy i generowania ludzkiego języka w sposób, który jest zarówno wartościowy, jak i funkcjonalny \cite{aggarwal2018textbook}. \akronim{NLP} obejmuje szereg technik i metod, które pozwalają na wydobywanie znaczenia z tekstu w języku naturalnym, co jest kluczowe w systemach takich jak chatboty, wyszukiwarki internetowe czy asystenci głosowi.
	
	Z punktu widzenia technologii, NLP jest ściśle powiązane z takimi dziedzinami jak lingwistyka komputerowa, uczenie maszynowe, analiza tekstu i statystyka. W ciągu ostatnich kilku lat, dzięki postępom w głębokich sieciach neuronowych i modelach językowych, NLP osiągnęło ogromny postęp, umożliwiając bardziej precyzyjne rozumienie i generowanie tekstu.
	
	Jednym z najważniejszych osiągnięć w dziedzinie NLP jest koncepcja \definicja{osadzenia słów} (\english{word embeddings}), które stanowią matematyczne reprezentacje słów w przestrzeni wektorowej. Celem osadzenia słów jest odwzorowanie słów w przestrzeni, w której słowa o~podobnym znaczeniu mają podobne reprezentacje numeryczne, czyli znajdują się blisko siebie w tej przestrzeni.
	
	Do najbardziej popularnych algorytmów tworzenia osadzeń słów należą modele \definicja{Word2Vec} \cite{aggarwal2018textbook}, \definicja{GloVe} \cite{pennington2014glove} oraz nowsze podejścia oparte na transformatorach, takie jak \definicja{BERT} \cite{devlin2018bert} czy \definicja{GPT} \cite{radford2019gpt2}. W tych modelach każde słowo w tekście jest reprezentowane przez wektor liczb, który odzwierciedla jego semantykę oraz kontekst użycia. Modele te bazują na analizie kontekstów słów w dużych korpusach tekstów, co pozwala na wyłapywanie zależności pomiędzy słowami.
	
	Szczególnie istotnym rozszerzeniem jest \definicja{Sentence-BERT (SBERT)}, umożliwiający tworzenie wektorów reprezentujących całe zdania, co czyni go niezwykle użytecznym w klasyfikacji tekstu, wyszukiwaniu informacji czy dopasowaniu zapytań \cite{reimers2019sentencebert}.

	\section{Klasyfikatory intencji}
	% TODO: odpowiedniej czego
	Klasyfikator intencji jest mechanizmem, który ma na celu przypisanie zapytania użytkownika do odpowiedniej  \cite{aggarwal2018textbook}. W kontekście NLP klasyfikatory intencji najczęściej wykorzystują osadzenia słów oraz różne techniki dopasowania, takie jak podobieństwo kosinusowe, do porównania zapytań z wcześniej zdefiniowanymi przykładami. Celem tych systemów jest przypisanie odpowiedniego kontekstu do zapytania, co pozwala na efektywne sterowanie aplikacjami lub systemami, jak np. asystenci głosowi, chatboty czy systemy rekomendacji.
	
	\definicja{Intencje użytkowników} są zazwyczaj definiowane poprzez zestaw fraz, które mogą być używane przez użytkownika do wyrażenia swojej woli. Każda fraza przypisana jest do określonej intencji, a klasyfikator intencji jest odpowiedzialny za przypisanie zapytania użytkownika do jednej z tych intencji.
	
	Klasyfikacja intencji jest realizowana przez modele oparte na głębokich sieciach neuronowych, które są trenowane na dużych zbiorach danych. Modele te uczą się rozpoznawania wzorców w tekstach, dzięki czemu mogą efektywnie klasyfikować zapytania do odpowiednich kategorii. Wykorzystanie technik takich jak osadzenia słów oraz podobieństwo kosinusowe pozwala na efektywne porównanie zapytań użytkowników z wcześniej zdefiniowanymi intencjami, co pozwala na przypisanie odpowiednich akcji lub odpowiedzi w systemach bazujących na NLP.

	Po utworzeniu osadzenia słów, kolejnym krokiem w NLP jest ocena podobieństwa między różnymi wektorami. Najczęściej używaną miarą w tym przypadku jest podobieństwo kosinusowe (\english{cosine similarity}), które mierzy kąt między dwoma wektorami w przestrzeni wektorowej. Miara ta jest szczególnie użyteczna, ponieważ daje wynik w zakresie od -1 do 1, gdzie wartość 1 oznacza wektory identyczne, wartość -1 oznacza wektory całkowicie przeciwne.

	Matematyczna ocena pokrewieństwa semantycznego między zapytaniem a bazą wzorców opiera się na analizie geometrii wektorów, a nie na bezpośrednim dopasowywaniu znaków. Kluczowym narzędziem wykorzystywanym w tym procesie jest podobieństwo kosinusowe (ang. \textit{cosine similarity}), które mierzy cosinus kąta między dwoma wektorami w przestrzeni 1024-wymiarowej. Wybór tej metryki, opisanej wzorem (\ref{eq:cosine}), wynika z jej odporności na różnice w długości tekstów; w systemach NLP istotny jest kierunek wektora, reprezentujący temat wypowiedzi, a nie jego norma (długość), która często zależy jedynie od liczby użytych słów.

	\begin{equation}
		\text{similarity}(A, B) = \cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \sqrt{\sum_{i=1}^{n} B_i^2}} 
		\label{eq:cosine}
	\end{equation}

	Wartość tej miary oscyluje w granicach od -1 do 1, gdzie 1 oznacza identyczność semantyczną. Dzięki temu system jest w stanie poprawnie zakwalifikować zapytania takie jak ,,Dodaj wizytę kowala'' oraz ,,Kowal był u konia'', mimo że na poziomie leksykalnym dzielą one jedynie jedno słowo kluczowe \cite{han2011}.

	W kontekście klasyfikacji intencji, podobieństwo kosinusowe pozwala na ocenę, jak blisko w~przestrzeni wektorowej znajdują się zapytania użytkowników względem dostępnych przykładów \cite{aggarwal2018textbook}. Dzięki temu możliwe jest przypisanie odpowiednich końcówek \termdef{Application Programming Interface} \akronim(API) do zapytań użytkowników w systemach sterowanych językiem naturalnym.

	Współczesne podejścia coraz częściej wykorzystują modele oparte na transformatorach, które umożliwiają rozpoznawanie intencji nawet w kontekście nieznanych wcześniej sformułowań (\definicja{few-shot} lub \definicja{zero-shot learning}) \cite{brown2020language}. Takie podejście sprawia, że systemy NLP są znacznie bardziej elastyczne i odporne na wariacje językowe użytkowników.
	
	\section{Transformatory i mechanizm uwagi}
	
	Transformatory to jedna z najnowszych i najbardziej przełomowych architektur w dziedzinie NLP, wprowadzona przez Vaswaniego i współpracowników w \cite{vaswani2017attention}. Głównym celem tej architektury było poprawienie efektywności modeli językowych poprzez wyeliminowanie rekurencyjnych warstw, które były wykorzystywane w poprzednich modelach, takich jak LSTM \cite{hochreiter1997lstm} i GRU \cite{cho2014gru}. Transformator jest oparty na mechanizmie samo-uwagi (\english{self-attention}), który umożliwia modelowi analizowanie wszystkich słów w zdaniu równocześnie i decydowanie o tym, które słowa są najbardziej istotne w kontekście innych słów.
	
	Mechanizm uwagi (\english{attention mechanism}) jest kluczowym elementem działania transformatora i służy do ważenia różnych słów w zdaniu na podstawie ich istotności. Działa to w następujący sposób: dla każdego słowa w zdaniu model przypisuje wagę, która zależy od tego, jak ważne jest to słowo w kontekście innych słów w zdaniu. Dzięki temu, model może uwzględnić nie tylko lokalne zależności między słowami, ale także globalne konteksty, co znacznie poprawia jakość przetwarzania informacji.
	
	W mechanizmie uwagi transformatora każdy token, czyli jednostka tekstu, na jaką model językowy dzieli dane wejściowe, jest reprezentowany przez trzy wektory: zapytanie (\english{query}), klucz (\english{key}) oraz wartość (\english{value}). Wagi uwagi oblicza się na podstawie iloczynu skalarnego zapytania i klucza, a następnie stosuje się funkcję \textit{softmax}, aby uzyskać rozkład prawdopodobieństwa nad wszystkimi słowami. Na przykład, w zdaniu:  \textit{„Właściciel konia chce dodać nową klacz do hodowli”},  token \textit{„właściciel”} może otrzymać wysoką wagę względem słów \textit{„chce”} i \textit{„klacz”}, ponieważ to one definiują działanie użytkownika.
	
	Największą zaletą transformatorów w porównaniu do wcześniejszych modeli rekurencyjnych, takich jak LSTM\cite{hochreiter1997lstm} czy GRU\cite{cho2014gru}, jest ich zdolność do równoczesnego przetwarzania wszystkich słów w zdaniu (równoległość), co znacznie przyspiesza proces trenowania. Ponadto, dzięki mechanizmowi uwagi, modele transformatorów są w stanie uchwycić długoterminowe zależności w tekście, co jest trudne do osiągnięcia w modelach sekwencyjnych.
	
	Transformatory stały się podstawą dla wielu dużych modeli językowych: \definicja{BERT} \cite{devlin2018bert}, \definicja{GPT-2} \cite{radford2019gpt2}, \definicja{GPT-3} \cite{brown2020language}, które osiągnęły znaczące sukcesy w zadaniach NLP, takich jak klasyfikacja tekstów \cite{devlin2018bert}, tłumaczenie maszynowe \cite{vaswani2017attention}, generowanie tekstu \cite{brown2020language}, odpowiedzi na pytania \cite{devlin2018bert} czy analiza sentymentu \cite{devlin2018bert}.

    Ostatni etap rozwoju NLP to pojawienie się \definicja{dużych modeli językowych} (\akronim{LLM}, \english{Large Language Models}), które wykorzystują miliardy parametrów do modelowania języka na podstawie ogromnych korpusów danych. Modele te, oparte na architekturze transformatora, potrafią wykonywać złożone zadania, takie jak tłumaczenie, streszczanie, generowanie kodu czy prowadzenie rozmowy \cite{openai2023gpt4technicalreport}.
    
    Jednym z najnowszych osiągnięć jest seria modeli \definicja{Gemini}, opracowana przez Google DeepMind. \definicja{Gemini 2.5 Flash}, łączy multimodalność (obsługuje tekst, obraz, dźwięk i wideo) z długim kontekstem przekraczającym milion tokenów. Model ten posiada zdolność wnioskowania -- tzn. rozwiązywania problemów poprzez wieloetapowe rozumowanie i planowanie działań, co określane jest mianem „\definicja{thinking model}” \cite{deepmind2025gemini}.  
    Dzięki integracji z narzędziami (\definicja{tool use} / \definicja{function calling}), Gemini 2.5 Flash może wykonywać rzeczywiste operacje -- np. wywoływać API, generować zapytania REST czy wykonywać obliczenia. W kontekście niniejszej pracy model ten może zatem nie tylko klasyfikować intencje użytkowników, ale także automatycznie generować odpowiednie żądania HTTP, umożliwiając naturalne sterowanie aplikacją webową.  
    Mimo wysokiej skuteczności, LLM-y takie jak Gemini 2.5 Flash nadal wymagają dużych zasobów obliczeniowych i mogą generować nieścisłości semantyczne, znane jako \definicja{halucynacje} \cite{bommasani2021opportunities}.

	\section{Podsumowanie}
	
	Przetwarzanie języka naturalnego stanowi jeden z fundamentów współczesnych systemów inteligentnych, umożliwiając komputerom interakcję z użytkownikami w sposób zbliżony do ludzkiego. Modele osadzania słów, takie jak Word2Vec, GloVe, BERT czy Sentence-BERT, stanowią podstawę nowoczesnych rozwiązań NLP, pozwalając na analizę i klasyfikację tekstów. Dopasowanie kosinusowe jest jedną z najczęściej stosowanych miar podobieństwa, umożliwiającą efektywne porównywanie zapytań użytkowników z przykładami intencji w systemach klasyfikacji. Klasyfikatory intencji, oparte na tych technologiach, umożliwiają skuteczne przypisanie zapytań do odpowiednich działań w aplikacjach, takich jak chatboty czy asystenci głosowi.
	
	Współczesne modele oparte na mechanizmie uwagi, takie jak transformatory, zrewolucjonizowały dziedzinę NLP, oferując wydajność i dokładność, które były niemożliwe do osiągnięcia w poprzednich modelach. Dzięki transformatorom możliwe stało się przetwarzanie długich tekstów oraz uchwycenie głębokich, globalnych zależności w tekście.
	Od prostych modeli osadzania słów, przez transformery, aż po duże modele językowe -- rozwój NLP umożliwia coraz bardziej naturalną interakcję człowieka z komputerem. Zastosowanie LLM, takich jak \definicja{Gemini 2.5 Flash}, otwiera nowe możliwości dla aplikacji sterowanych językiem naturalnym, w tym systemu \definicja{Moje Konie}, w którym polecenia użytkownika mogą być tłumaczone bezpośrednio na żądania REST w sposób kontekstowo poprawny i semantycznie spójny.
	
