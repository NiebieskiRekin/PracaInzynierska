\chapter{Architektura systemu}

\section{Założenia projektowe}

Głównym celem systemu \definicja{Moje Konie} jest cyfryzacja procesów zarządzania stajnią oraz dostarczenie hodowcom narzędzia umożliwiającego kompleksowe monitorowanie stanu zdrowia i historii koni. Projekt został oparty na analizie wymagań funkcjonalnych i pozafunkcjonalnych, wynikających ze specyfiki pracy w terenie (stajnia, pastwisko) oraz konieczności przetwarzania danych poufnych. Poniżej przedstawiono kluczowe założenia, które ukształtowały architekturę rozwiązania.

\subsection{Założenia funkcjonalne}

Centralnym elementem systemu jest moduł ewidencji koni, zapewniający jednoznaczną identyfikację zwierząt. Karta każdego konia agreguje szczegółowe dane, w tym numer przyżyciowy, numer chipa, rocznik urodzenia, płeć, daty przybycia i odejścia, fotografie, a także najnowsze aktywne wydarzenia związane z danym koniem, takie jak podkucia, szczepienia, odrobaczanie, podanie suplementów czy wizyty dentystyczne. Wymieniony numer przyżyciowy to unikalny kod nadawany koniowi, zapisany w jego paszporcie, który wraz z numerem transpondera (chipa) i danymi właściciela służy do jego pełnej identyfikacji, zapobiegając nielegalnemu obrotowi, a także umożliwia śledzenie zdrowia, szczepień i pochodzenia \cite{TODO}. Obsługa zdjęć zakłada możliwość dodawania wielu fotografii do jednego obiektu oraz ich wygodne przeglądanie.

Kluczową funkcjonalnością z perspektywy codziennej pracy hodowcy jest zarządzanie zdarzeniami. System umożliwia rejestrację i kategoryzację interwencji takich jak: usługi weterynaryjne (szczepienia, odrobaczania, wizyty dentystyczne), usługi kowalskie (podkucia) oraz suplementacja. W celu usprawnienia wprowadzania danych, proces ten wspierany jest przez mechanizmy podpowiedzi (sugerowanie powiązanych specjalistów) oraz operacje masowe (możliwość przypisania jednego zdarzenia do wielu koni jednocześnie).

Dopełnieniem funkcjonalności są moduły raportowania i powiadomień. Aplikacja pozwala na generowanie zestawień historii leczenia i zabiegów w zadanym przedziale czasowym, co jest niezbędne np. podczas sprzedaży konia lub kontroli weterynaryjnej. System wspiera użytkownika poprzez mechanizm konfigurowalnych powiadomień (e-mail) o zbliżających się terminach wygaśnięcia ważności istotnych zdarzeń, takich jak szczepienia czy podkucia. Użytkownik posiada pełną kontrolę nad preferencjami powiadomień, definiując czas wyprzedzenia (w dniach i godzinach) dla poszczególnych alertów.

Interakcja z systemem wspierana jest przez inteligentnego asystenta, który ułatwia nawigację i wyszukiwanie informacji, co stanowi istotne udogodnienie w kontekście rosnącej roli sztucznej inteligencji w oprogramowaniu użytkowym.

\subsection{Założenia pozafunkcjonalne} \label{sec:pozafunkcjonalne}

Ze względu na charakter pracy użytkowników końcowych, priorytetem stała się dostępność i ergonomia interfejsu. Przyjęto założenie pełni funkcjonalności na urządzeniach mobilnych używanych bezpośrednio w stajni, jak i na komputerach biurowych. Zrealizowano to poprzez responsywny interfejs użytkownika (\english{Responsive Web Design})\cite{TODO}, który dynamicznie dostosowuje układ treści (np. lista koni w formie jednej kolumny na telefonie i trzech na monitorze).

W aspekcie bezpieczeństwa przyjęto rygorystyczne standardy ochrony danych. Dostęp do systemu jest chroniony procesem uwierzytelniania (e-mail oraz hasło), a same hasła przechowywane są w bazie danych wyłącznie w postaci bezpiecznych skrótów kryptograficznych (\english{hash}), co uniemożliwia ich odtworzenie. System realizuje strukturę wielodostępową (\english{multi-tenancy}) na poziomie logicznym, gdzie użytkownik po zalogowaniu uzyskuje autoryzację wyłącznie do zasobów przypisanych do jego hodowli. Wszelkie operacje krytyczne, takie jak usuwanie danych, wymagają dodatkowego potwierdzenia. i działają w trybie łagodnego usuwania (\english{soft delete}). Oznacza to, że rekord nie jest fizycznie usuwany z bazy danych, lecz następuje jedynie zmiana wartości logicznej w dedykowanej kolumnie \texttt{active}. Formularze edycyjne wyposażono w walidację danych wejściowych, aby zapewnić ich integralność.

System zaprojektowano z myślą o wydajności pozwalającej na obsługę 400 zarejestrowanych użytkowników, przy założeniu do 100 jednoczesnych sesji. Architektura rozwiązania ma na celu minimalizację kosztów utrzymania oraz uproszczenie procesów administracyjnych, co ma kluczowe znaczenie dla długoterminowej trwałości projektu.

\section{Opis architektury aplikacji}

Realizacja powyższych założeń, w szczególności wymogu dostępności na wielu platformach sprzętowych oraz centralizacji danych, podyktowała wybór architektury systemu webowego z przeglądarkowym interfejsem użytkownika. Aplikacje internetowe pozwalają na wykorzystanie bogatego i dojrzałego zaplecza technologicznego do wyświetlania stron internetowych, co znacząco upraszcza aspekt dystrybucji oprogramowania oraz współbieżnego dostępu do danych. 

Dla zachowania kompatybilności z technologią progresywnych aplikacji internetowych (\english{Progressive Web App}, \akronim{PWA})\cite{TODO} oraz modularności zdecydowano się na podział aplikacji na trzy części:

\begin{enumerate}
    \item \textbf{Backend (warstwa serwerowa)}: Odpowiada za logikę biznesową, przetwarzanie danych, autoryzację, komunikację z bazą danych oraz integrację z usługami zewnętrznymi (np. asystentem NLP). Jest to komponent, z którym zwykły użytkownik nie wchodzi w bezpośrednią interakcję. Został on zaimplementowany jako bezstanowy interfejs programistyczny w architekturze REST (\english{Representational State Transfer})\cite{TODO}, wymieniający dane w formacie JSON.
    \item \textbf{Frontend (warstwa klienta)}: Odpowiada za prezentację danych i interakcję z użytkownikiem. Uruchamiana jest bezpośrednio w przeglądarce internetowej użytkownika. Inicjuje ona zapytania do serwera (backendu) w celu pobrania lub modyfikacji danych.
    \item \textbf{Klasyfikator (dodatkowa usługa serwera)}: Model bazujący osadzeniach wektorowych w celu odwzorowania żądania użytkownika na odpowiednią końcówkę API backendu. Również skonfigurowany do działania jako bezstanowy interfejs programistyczny wymieniający dane w formacie JSON. Z uwagi na wysoką wagę tego rozwiązania w kontekście pracy został mu zadedykowany osobny,  zawierający pełen opis architektury rodział \ref{sec:klasyfikator}: \nameref{sec:klasyfikator}.
\end{enumerate}

Komunikacja między warstwami frontendu i backendu odbywa się w warstwie 7 modelu ISO/OSI (warstwa aplikacji) z wykorzystaniem szyfrowanego protokołu HTTPS, co zapewnia poufność przesyłanych informacji. W przypadku komunikacji backendu z klasyfikatorem wykorzysytany został prostszy protokół HTTP ze względu na fakt użycia izolowanej wirtualnej sieci wewnątrz tego samego systemu operacyjnego. Taki podział architektoniczny (model klient-serwer) umożliwia niezależny rozwój części systemu, a także ułatwia skalowanie wybranej warstwy serwerowej w odpowiedzi na zwiększone obciążenie.

Ze względu na wymóg współbieżnego, spójnego dostępu do danych o złożonych, ale stabilnych relacjach został wybrany system zarządzania relacyjną bazą danych \textit{PostgreSQL}\cite{TODO}. Spośród dostępnych na rynku rozwiązań wyróżnia się on brakiem opłat licencyjnych, bogatą dokumentacją, bardzo dobrą optymalizacją przetwarzania na małych i średnich zbiorach danych, obszernym zestawem funkcji, a także jest dobrze znany i lubiany przez zespół projektowy. Dostęp do bazy danych i przekazanie danych do warstwy prezentacji jest realizowane przez backend, co jest jego głównym zadaniem w kontekście aplikacji. Zostało to szczegółowo opisane w rozdziale \ref{sec:backend}: \nameref{sec:backend}. 

% Traefik

% Dodatkowo aplikacja w swojej implementacji wykorzystuje szereg zewnętrznych usług:
% \begin{enumerate}
%     \item Cloudflare -- DNS i filtrowanie ruchu
%     \item Let's encrypt -- wystawienie certyfiaktu TLS
%     \item Google Cloud Platform Firewall -- zapora sieciowa
%     \item Gemini LLM -- przetwarzanie słownych zapytań użytkownika na żądania REST
%     \item Gmail -- powiadomienia E-mail
%     \item Google Cloud Platform Object Storage Bucket - miejsce przechowywania zdjęć
% \end{enumerate} 

\section{Frontend}

Korzystając z technologii progresywnych aplikacji internetowych (\english{Progressive Web App}, \akronim{PWA}) oraz praktyki responsywnego projektowania stron internetowych (\english{responsive web design}, \akronim{RWD}) zaimplementowano spójny interfejs użytkownika dla platform mobilnych. Do implementacji technologii progresywnych aplikacji internetowych wymagane jest, aby interfejs graficzny użytkownika był skomponowany w zdecydowanej większości ze statycznych dokumentów hipertekstowych HTML (HyperText Markup Language), arkuszy stylów CSS (Cascading Style Sheets) oraz kodu w języku programowania JavaScript. Statyczne pliki w podanym kontekście oznaczają podleganie nieczęstym zmianom poprzez pobranie zaktualizowanej wersji z serwera -- wyłącznie między oddzielnymi wydaniami aplikacji i nigdy w celu wyświetlenia nowych danych.

Interaktywna prezentacja danych jest możliwa natomiast poprzez zmianę struktury wyświetlanego dokumentu hipertekstowego wykonywaną po stronie klienta z użyciem kodu JavaScript w przeglądarce. Wymienione działanie jest wykonywane poprzez interfejs programowania Modelu Obiektowego Dokumentu  (\english{Document Object Model}, \akronim{DOM})\cite{TODO} pozwalający na częściową lub pełną modyfikację dowolnego węzła (np. akapitu tekstu, separatora, kontrolek, obiektu multimedialnego) w hierarchicznej strukturze drzewa dokumentu HTML. Interfejs ten jest w praktyce wykorzystywany przez bibliotekę \textit{React}\cite{TODO}, która nieco modyfikuje model z dokumentów HTML i skryptów JavaScript na komponenty wielokrotnego użytku (zawierające wymagane fragmenty dokumentu HTML i funkcje JavaScript) budujące deklaratywne widoki (strony internetowe). Komponenty można powiązać z danymi, czyli zaprojektować ich wygląd w celu prezentacji danych zgodnie z ich schematem oraz skonfigurować ich źródło, które będzie automatycznie odświeżane, dążąc do zadeklarowanego stanu. Komponenty można w sobie zagnieżdżać, odtwarzając te same aspekty hierarchicznej struktury, a ich zmiany są śledzone poprzez użycie wewnętrznej dla tej biblioteki kopii Modelu Obiektowego Dokumentu nazywanego Wirtualnym Model Obiektowym Dokumentu (\english{Virtual DOM}).

Opisane podejście nazywa się \textit{aplikacją jednostronicową} (\english{Single-page application}, \akronim{SPA})\cite{TODO}, co wynika głównie ze sposobu aktualizowania interfejsu na podstawie zmian w danych poprzez kod po stronie klienta i przesyłania statycznych dokumentów HTML, pomijając jednocześnie aspekt użycia wielu stron. W przypadku prezentowanej pracy rama projektowa (\english{framework}) została dostarczona przez bibliotekę \textit{React Router}\cite{TODO}, która dostarcza narzędzie budujące (\english{build tool}) do aplikacji jednostronicowej, dostarczając ponadto zestaw narzędzi służących do przechodzenia pomiędzy osobnymi widokami w zależności od użytego adresu URL -- nazwany router, a także moduły do efektywnego pobierania danych w tle za pomocą funkcji asynchronicznych.

% TODO: przekopiuj od Kuby

\section{Backend} \label{sec:backend}

Przetwarzanie wykonywane po stronie serwera jest realizowane w znacznej części przez komponent backendu. Został on zaimplementowany jako bezstanowy interfejs programowania REST, który obsługuje komunikację za pomocą danych serializowanych do formatu JSON. Integruje on między sobą wiele komponentów, co zostało pokazane na diagramie architektury sieciowej, przedstawionym na Rysunku \ref{rys:architektura-sieciowa}. Jego głównym zadaniem jest udostępnienie dostępu do danych zapisanych w bazie danych przez protokół HTTP interfejsu sieciowego na warstwie 7 modelu ISO/OSI.

\begin{figure}[t]
\centering\includegraphics[width=\textwidth]{figures/architektura-sieciowa}
\caption{Architektura sieciowa aplikacji}\label{rys:architektura-sieciowa}
\end{figure}

Rola serwera HTTP jest spełniana przez ramę projektową biblioteki \textit{Hono}\cite{TODO}. Biblioteka ta pozwala na bardzo modularne tworzenie silnie typowanych końcówek (\english{endpoint}), warstw pośrednich przetwarzania (\english{middleware}) i elastyczne łączenie ich w poszczególne ścieżki obsługiwane współbieżnie i wydajnie przez jeden z kilku dostępnych silników dopasowań (\english{router}).

W celu zapewnienia współbieżnego dostępu do bazy danych zapytania są realizowane przez bibliotekę \textit{node-postgres}, która głównie zarządza tworzeniem puli połączeń do bazy danych. Biblioteka ta jest rozszerzana przez bibliotekę \textit{DrizzleORM}\cite{TODO} w celu utworzenia odwzorowania obiektowo-relacyjnego (\akronim{ORM}, \english{Object-Relational mapping}) struktur obiektów utworzonych w języku TypeScript na relacje bazy danych w języku SQL, napisania zoptymalizowanych zapytań do bazy danych, utworzenia migracji pomiędzy wersjami schematu tabel w procesie tworzenia aplikacji i jej wdrożenia, a także wypełniania bazy danych początkowymi danymi. Biblioteka \textit{DrizzleORM} charakteryzuje się zbliżoną składnią, co język SQL, dzięki czemu dobra znajomość tworzenia zapytań przez zespół premiowała dobrą optymalizacją przepływu danych i prostszym, wydajniejszym modelem abstrakcji. Każde poprawne zapytanie utworzone z użyciem \textit{DrizzleORM} jest konwertowane na dokładnie jedno zapytanie do bazy danych, a przygotowane wcześniej zapytania można było przepisać z małymi zmianami składni. 

Dzięki podejściu do połączenia z bazą danych z niewielką warstwą abstrakcji możliwe było wykorzystanie bardziej zaawansowanych funkcjonalności bazy danych PostgreSQL, takich jak:
\begin{itemize}
    \item użycie schematów jako dynamicznego zamiennika osobnych baz danych dla różnych, odseparowanych środowisk na tym samym serwerze (dla środowiska testowego i produkcyjnego),
    \item reprezentacja typów wyliczeniowych z użyciem \texttt{pg\_enum} (m.in. do rodzajów koni i zdarzeń profilaktycznych),
    \item filtrowanie powiadomień do wysłania względem różnicy czasu wyliczanej po stronie silnika PostgreSQL,
    \item grupowanie kilku zapytań w jedno dzięki składni \texttt{UNION} (wykorzystywane przy pobieraniu zdarzeń profilaktycznych),
    \item użycie podzapytań z klauzulami \texttt{NOT EXISTS} (do znalezienia czy istnieje domyślne zdjęcie dla danego konia przy usuwaniu),
    \item konstrukcja \texttt{PARTITION BY} do znalezienia najnowszych aktywnych zdarzeń profilaktycznych z każdej kategorii dla danego konia.
\end{itemize}

\textit{DrizzleORM} jednocześnie dostarcza pełne interfejsy i typy danych oczekiwane przez język TypeScript, a nawet schematy walidacji do biblioteki walidacyjnej \textit{Zod}\cite{TODO}, dzięki dodatkowi \textit{drizzle-zod}. Pozwoliło to w procesie tworzenia aplikacji na zachowanie spójności w przepływie danych oraz zaoszczędzenie czasu na pisanie złożonych definicji schematów. Wykorzystanie biblioteki \textit{Zod} stanowi istotny element pracy, gdyż ze względu na zaawansowane i ergonomiczne funkcje walidacji, a także ogromną popularność biblioteka stała się standardem w środowisku TypeScript do tworzenia modeli danych. \textit{Zod} pozwala na zdefiniowanie schematów opisujących układ pól i ograniczenia danych, a następnie weryfikować wartości dowolnych, niesprawdzonych obiektów przyjmowanych przez program, aby przetransformować lub potwierdzić poprawność z założonym formatem danych. Cenną funkcją biblioteki \textit{Zod} jest zwracania szczegółowej, ustrukturyzowanej listy niezgodności ze schematem w trakcie walidacji. 

Zbiory powiązanych schematów można połączyć w rejestry, co pozwala powiązać je z dodatkowymi ustrukturyzowanymi metadanymi. Gotowe schematy można również obustronnie konwertować do formatu zgodnego ze specyfikacją JSON Schema\cite{TODO}, w tym OpenAPI\cite{TODO}. Wymieniona specyfikacja OpenAPI zapewnia spójny sposób przesyłania informacji na każdym etapie cyklu życia API. Jest to język specyfikacji dla interfejsów API HTTP, który definiuje strukturę i składnię w sposób niezależny od języka programowania, w którym utworzono API. Ekosystem narzędzi powiązany z tym rozwiązaniem jest bardzo bogaty i dostarcza wiele rozwiązań generujących w pełni zautomatyzowany sposób gotową implementację (zdefiniowanej części sieciowej) klienta bądź serwera dla danej specyfikacji. Specyfikacje te są pisane w formatach YAML lub JSON, co umożliwia łatwe udostępnianie i ich wykorzystanie.

Dzięki użyciu biblioteki \texttt{@hono/zod-validator} dla każdej końcówki API Hono zdefiniowano schemat oczekiwanych danych. Wykorzystanie funkcji \texttt{zValidator} z tej samej biblioteki umożliwiło automatyczną walidację zgodności danych wejściowych ze schematem. Elastyczność rozwiązania powoduje, że walidacja jest przeprowadzana niezależnie czy dane są przekazywane jako element ścieżki wyszukiwania (\english{query parameters}), dane JSON w ciele żądania, czy zgodnie z typem \texttt{multipart/form-data} bądź \texttt{application/form-data}. Dodatkowo zestaw powiązanych bibliotek \textit{hono-openapi} i \textit{@hono/zod-openapi} pozwolił na dodanie adnotacji do dokumentacji danej końcówki w formacie OpenAPI oraz zdefiniowanie schematu zwracanych danych w zależności od kodu odpowiedzi. Wygenerowana dokumentacja w uniwersalnym formacie OpenAPI z całego backendu posłużyła jako wzorzec do tworzenia zapytań przez Gemini w procesie przetwarzania intencji użytkownika. Również dzięki interfejsowi graficznemu dostarczanemu przez bibliotekę \textit{Scalar}\cite{TODO} do obsługi dokumentacji OpenAPI niewielkim nakładem pracy utworzono zaawansowany panel administracyjny do zarządzania użytkownikami i stadninami przez administratorów. Został on przedstawiony dokładniej w rozdziale \ref{sec:panel-administracyjny}: \nameref{sec:panel-administracyjny}. Schematy \textit{Zod} wykorzystywane są również do walidacji konfiguracji zmiennych środowiskowych wymaganych do poprawnego działania aplikacji. 

\subsection{Kontrola dostępu} \label{sec:kontrola-dostepu}

Aplikacja \definicja{Moje Konie} korzysta ze scentralizowanego, zintegrowanego z kodem aplikacji systemu uwierzytelniającego. W celu zapewnienia bezpiecznego systemu uwierzytelniającego skorzystano z zewnętrznej biblioteki \textit{BetterAuth}\cite{TODO}, która dostarczyła komponenty do zarządzania użytkownikami, kontami, hodowlami koni w kontekście organizacji i przynależnościami do nich. Biblioteka wykorzystuje PostgreSQL jako magazyn danych i tworzy automatycznie wymagane relacje poprzez integracje z DrizzleORM. Konta użytkowników mogą zostać tworzone wyłącznie przez użytkownika z grupy administratorów, nie jest możliwa rejestracja zewnętrzna bezpośrednio przez użytkownika. Uwierzytelnianie odbywa się wyłącznie za pomocą adresu e-mail i hasła, a adresy e-mail muszą zostać potwierdzone poprzez link. Użytkownicy mają możliwość zmiany ustawionego hasła, a po zakończeniu tego procesu następuje unieważnienie wszystkich aktywnych sesji, co powstrzymuje przed dostępem z potencjalnie przejętych urządzeń.

Zarządzanie sesjami realizowane jest poprzez mechanizm ciasteczek i zapisanie aktywnych sesji w bazie danych. W celu optymalizacji wydajności i redukcji obciążenia bazy danych przy sekwencyjnych żądaniach wykorzystano mechanizm pamięci podręcznej ciasteczek wynoszący 5 minut. Dzięki temu backend, zamiast wypytywać bazę danych dla każdego przychodzącego żądania wymagającego uwierzytelnienia, może potwierdzić daną sesję z ciasteczka podpisanego kryptograficznie. Takie ciasteczko trafia następnie do przeglądarki użytkownika. Podpisy i potwierdzenia są realizowane przez backend z użyciem tajnego symetrycznego klucza (wyłącznie po stronie serwera) z użyciem funkcji skrótu \emph{HMAC-SHA256}\cite{TODO}. Po upłynięciu ustalonego czasu wygaśnięcia pamięci podręcznej kolejne żądanie wymagające uwierzytelnienia będzie powodowało utworzenie zapytania do bazy danych o potwierdzenie sesji użytkownika i generowało nowe podpisane ciasteczko. Sesje użytkowników mają długi czas wygasania wynoszący 30 dni, w którego trakcie ważność sesji jest automatycznie odświeżana przy aktywności użytkownika raz na 24 godziny. Ma to na celu utrzymywanie poprawnej sesji (stanu bycia zalogowanym do strony) na czas dostatecznie długi, aby nie stanowił problemu dla aktywnych i powracających po niedługich odstępach czasu użytkowników. Długość ważności sesji jest podyktowana zarządzaniem danymi o nieczęstej zmienności i niską potrzebą codziennego pobierania danych przez użytkowników.

Pozostałe aspekty ciasteczek sesyjnych skonfigurowano z naciskiem na bezpieczeństwo zgdonie z aktualnymi wytycznymi\cite{TODO}. Flaga \emph{SameSite} ustawiona na \emph{Strict} wymusza pełną zgodność nazwy domenowej serwera, z którym następuje połączenie w odniesieniu do serwera, który ustawił dane ciasteczko, co pomaga zapobiegać atakom polegającym na wymuszaniu nieautoryzowanej akcji w przeglądarce ofiary takim jak \emph{Cross Site Request Forgery} (\akronim{CSRF}). Atrybut \emph{HttpOnly} zabrania dostępu do wartości danego ciasteczka sesji przez kod JavaScript w przeglądarce klienta, co ponownie zawęża możliwe ataki z użyciem złośliwych skryptów takie jak \emph{Cross Site Scripting} (\akronim{XSS}). Finalnie flagi \emph{Secure} oraz \emph{Partitioned} są skonfigurowane zgodnie z zaleceniami przeglądarek i wymuszają odpowiednio poufność przez konieczność stosowania protokołu HTTPS, oraz izolację sesji użytkownika zgodnie z wytycznymi prywatności.

Warstwa autoryzacji wykorzystuje model kontroli dostępu opartej na 2 rolach (admin, user) oraz strukturę wielodostępową (\english{multi-tenancy}) poprzez tworzenie organizacji do zarządzania odrębnymi hodowlami. Domyślna rola użytkownika pozwala na zarządzanie cyklem życia (dodawanie, usuwanie, edycja) wszystkich zwykłych obiektów takich jak: konie, wydarzenia z nimi związane, zapisani specjaliści, a także ustawienia użytkownika. Rola administratora jest przeznaczona dla osób posiadających odpowiednie kompetencje do zarządzania całą instancją serwera. Zatem pozwala na dodawanie nowych i edycję istniejących kont użytkowników, hodowli, danych uwierzytelniających oraz na wszystkie uprawnienia nadane podstawowej roli użytkownika. Dodatkowo włączono obsługę kluczy API. Są to jednoskładnikowe dane uwierzytelniające służące do obsługi żądań do backendu poprzez interfejsy programistyczne. Klucze te mogą być wykorzystywane do automatyzacji części procesów aplikacji z zewnętrznymi usługami, a także posłużyć jako składnik uwierzytelniający w panelu administracyjnym. Warstwa autoryzacji integruje się z serwerem utworzonym przez \textit{Hono} poprzez udostępnienie końcówek autoryzacyjnych pod ścieżką \texttt{/api/auth}. Zestaw dostępnych funkcji udostępnionych przez bibliotekę \textit{BetterAuth} jest dołączony do dokumentacji reszty backendu formacie OpenAPI. Dzięki wykorzystaniu gotowego zestawu tłumaczeń komunikaty błędów funkcji \textit{BetterAuth} zostały przetłumaczone na język polski. W celu poprawy widoczności informacji diagnostycznych o incydentach kluczowe zdarzenia bezpieczeństwa są rejestrowane.

\subsection{Baza danych}

Aplikacja posiada bogaty model danych, co ma swoje odniesienie w złożonym modelu encji związków przedstawionym na Rysunku \ref{rys:schemat-bazy-danych}. W celu zachowania jak najlepszej spójności zastosowano znormalizowaną postać bazy danych, a dla ułatwienia edycji głównego identyfikatora sztuczne klucze główne. Aplikacja została zaprojektowana z myślą, aby obsługiwać wiele oddzielnych hodowli na jednej instancji aplikacji w modelu architektury wielodostępowej (\english{multi-tenant}). Ze względu na to założenie wszystkie obiekty dodawane przez użytkowników muszą mieć powiązanie z daną hodowlą, której nadany identyfikator rozdziela przynależność do danego klienta -- dzierżawcy. Podstawową funkcjonalnością aplikacji jest zarządzanie końmi, w tym przypisanie im imion, nr paszportowych, istotnych dat, a także hodowli, do której należą i innych danych charakterystycznych. Dodatkowo dla każdego konia można przypisać dowolną liczbę zdjęć, których podstawowe dane o przynależności są zapisywane w bazie danych (do którego konia, czy dane zdjęcie jest domyślne), natomiast same pliki są zapisywane w oddzielnej usłudze zoptymalizowanej do przechowywania plików binarnych \emph{Google Cloud Storage} w danym zasobniku co zostało opisane dokładniej w rozdziale \ref{sec:gcs}: \nameref{sec:gcs}.

\begin{figure}[t]
\centering\includegraphics[width=\textwidth]{figures/schemat-bazy.png}
\caption{Schemat bazy danych}\label{rys:schemat-bazy-danych}
\end{figure}


Dla każdego konia można przypisać wiele wydarzeń takich jak podkucia, choroby, leczenia, rozrody czy zdarzenia profilaktyczne. W przypadku podkuć, leczeń, rozrodów i zdarzeń profilaktycznych przypisywany jest również specjalista -- kowal lub weterynarz, powiązany z danym wydarzeniem. W przypadku specjalistów przechowywane dane są proste i ograniczają się do wskazania imienia, nazwiska, numeru telefonu i hodowli, w jakiej zostali dodani. Do podkuć, chorób i zdarzeń profilaktycznych przypisane są daty zdarzenia/rozpoczęcia oraz ważności/zakończenia, a do wszystkich wydarzeń poza podkuciami również opisy. Zdarzenia profilaktyczne posiadają również pole wyboru rodzaju zdarzenia spośród: odrobaczania, podania suplementów, szczepienia, dentysty i inne. Natomiast wydarzenia -- rozrody dzielą się na: inseminację konia, sprawdzenie źrebności, wyźrebienie i inne. Istotna jest również możliwość powiązania leczeń do danej choroby konia. Utworzona bezpośrednio została również tabela \emph{notifications}, która przechowuje preferencje użytkownika dotyczące powiadamiania o zbliżającym się końcu ważności danego wydarzenia z konfigurowalną liczbą dni wyprzedzenia, godziną powiadomienia i metodą wysłania.

Pozostałe tabele zostały utworzone przez bibliotekę BetterAuth i służą do zarządzania użytkownikami i ich przynależnością do danej hodowli (organizacji), uwierzytelniania i kontroli dostępu. Tabela \emph{organization} przechowuje informacje o hodowli, w tym dostępną liczbą zapytań do wykorzystania przez moduł \definicja{Asystenta NLP}. Tabela \emph{member} reprezentuje relację wiele do wielu pomiędzy tabelami \emph{organization} a \emph{user}, co pozwala odszukać przynależność użytkownika do danej hodowli, a także sprawdzić rolę konta (administrator, konto zwykłe). Tabele \emph{account} i \emph{apikey} przechowują dane uwierzytelniające dla danego użytkownika, głównie wykorzystywane jest hasło do uwierzytelniania zwykłych kont, natomiast klucz API do dostępu administracyjnego. W tabeli \emph{session} odnajdziemy informacje o aktywnych sesjach logowania użytkowników. Tabela \emph{verification} przechowuje informacje o wysłanych e-mailach z potwierdzeniem po założeniu konta. Natomiast tabela \emph{invitation} nie jest w praktyce wykorzystywana w projekcie i dotyczy zaproszeń użytkowników do organizacji przez innych użytkowników aplikacji (w praktyce dane konto użytkownika jest wyłącznie dla jednej organizacji).

\section{Google Cloud Storage} \label{sec:gcs}

\textit{Google Cloud Storage}\cite{TODO} jest usługą oferowaną i zarządzaną przez firmę \textit{Google}, w ramach której otrzymujemy dostęp do magazynu obiektowego (\english{Object Storage}). Różni się on od tradycyjnego systemu plików (jak dysk twardy z drzewem katalogów) tym, że dane istnieją w płaskiej strukturze wewnątrz danego \textit{zasobnika}. Zasobnik jest wydzieloną częścią usługi przydzieloną do danego projektu i funkcjonuje jako kontener bez dalszej hierarchii. Zasobniki posiadają globalnie unikalne nazwy, są przypisane do określonego regionu geograficznego, a także definiują polityki dostępu. 

Dane zapisywane do zasobnika są reprezentowane jako \textit{obiekty}. Odpowiadają one plikom, takim jak zdjęcia czy dokumenty tekstowe, bez ograniczeń dotyczących wewnętrznej struktury danych -- każdy format jest akceptowalny. O ile usługa potrafi wyświetlać przesłane obiekty w formie przypominającej katalogi, to w rzeczywistości struktura jest płaska, a foldery są odtwarzane wirtualnie na podstawie ukośników w nazwach plików. Dodatkowo obiekty w ramach magazynu nie są edytowalne fragmentami, a mogą być jedynie nadpisywane w całości, co pozwala na ich automatyczne wersjonowanie.

W aplikacji \definicja{Moje Konie} usługa magazynu obiektowego jest wykorzystywana do przechowywania zdjęć koni i udostępniania ich użytkownikom. W tym celu zaimplementowano wzorzec bezpośredniego dostępu autoryzowanego. Aby zoptymalizować wydajność i zredukować obciążenie sieciowe serwera (backendu), operacje przesyłania i pobierania plików zostały oddelegowane bezpośrednio do infrastruktury \textit{Google} z wykorzystaniem mechanizmu \textit{podpisanego odnośnika} (\english{Signed URL})\cite{TODO}. Aplikacja korzysta z biblioteki \texttt{@google-cloud/storage}, która upraszcza implementację tego procesu. Mechanizm udostępniania zasobów składa się z trzech kroków:

\begin{enumerate}
    \item \textbf{Konfiguracja tożsamości i kluczy}: Uwierzytelnianie procesu podpisywania odbywa się z użyciem pary kluczy asymetrycznych. Backend posiada klucz prywatny oraz identyfikator konta usługi (\english{Service Account}), które tworzą jego tożsamość ładowaną podczas startu aplikacji. Konto to posiada nadane uprawnienia do zarządzania zasobnikiem. Weryfikacja tych uprawnień nie następuje w momencie generowania linku przez backend, lecz jest odroczona do momentu faktycznej próby dostępu przez klienta.
    
    \item \textbf{Generowanie podpisanego żądania}: Gdy użytkownik chce wykonać operację na obiekcie, backend nie łączy się z usługą \textit{Google Cloud Storage}. Zamiast tego przygotowuje autoryzację zgodnie ze standardem \textit{GOOG4-RSA-SHA256}\cite{TODO}. Proces ten polega na zamianie parametrów planowanego żądania HTTP (metody, ścieżki do zasobu, nagłówków i czasu wygaśnięcia) w znormalizowany ciąg znaków. Następnie ciąg ten przekształcany jest w skrót \textit{SHA-256}, który zostaje zaszyfrowany kluczem prywatnym backendu. Ten zaszyfrowany skrót stanowi kryptograficzny podpis dołączany do adresu URL. Utworzony odnośnik ma ograniczony czas ważności, co minimalizuje ryzyko nieuprawnionego dostępu w przypadku jego przechwycenia.
    
    \item \textbf{Weryfikacja i transfer danych}: Klient (frontend) po otrzymaniu \textit{podpisanego odnośnika} wykonuje żądanie bezpośrednio do serwerów \textit{Google Cloud Storage}. W tym momencie infrastruktura chmury weryfikuje podpis, używając klucza publicznego przypisanego do konta usługi, oraz sprawdza ważność linku i uprawnienia. Jakakolwiek ingerencja w parametry adresu URL spowoduje niezgodność z podpisem i odrzucenie żądania. Po pomyślnej autoryzacji następuje transfer danych bezpośrednio między urządzeniem użytkownika a chmurą, z całkowitym pominięciem serwera aplikacji.
\end{enumerate}


\section{Charakterystyka wykorzystanych technologii wdrożeniowych}

Współczesne procesy wytwarzania i dostarczania oprogramowania opierają się na automatyzacji oraz standaryzacji środowisk uruchomieniowych. W celu realizacji niniejszego projektu wykorzystano zestaw narzędzi umożliwiających definicję infrastruktury w kodzie, jej automatyczną konfigurację oraz izolację procesów aplikacji. Poniżej przedstawiono charakterystykę kluczowych technologii wykorzystanych w procesie wdrożenia.

\subsection{Konteneryzacja i platforma Docker}

Konteneryzacja to metoda wirtualizacji na poziomie systemu operacyjnego, która pozwala na uruchamianie aplikacji w izolowanych przestrzeniach użytkownika, zwanych kontenerami. W przeciwieństwie do tradycyjnych maszyn wirtualnych, które wymagają emulacji całego sprzętu i uruchomienia pełnego systemu operacyjnego dla każdego systemu gościa, kontenery współdzielą jądro systemu operacyjnego gospodarza. Podejście to zmniejsza zapotrzebowanie na zasoby sprzętowe oraz przyspiesza czas uruchamiania aplikacji.

\textit{Docker}\cite{TODO} jest platformą technologiczną umożliwiającą tworzenie, wdrażanie i uruchamianie aplikacji w kontenerach. Architektura rozwiązania opiera się na kilku kluczowych pojęciach:

\begin{itemize}
    \item \textbf{Obraz} (\english{Image}) -- niezmienny szablon (artefakt) zawierający kod aplikacji, biblioteki, zależności oraz definicję środowiska uruchomieniowego. Obrazy budowane są warstwowo na podstawie pliku \texttt{Dockerfile} napisanego w języku dziedzinowym (\english{domain-specific language}). Użycie warstw pozwala na efektywne wykorzystanie pamięci masowej poprzez współdzielenie identycznych warstw między różnymi obrazami.
    \item \textbf{Kontener} (\english{Container}) -- instancja obrazu uruchomiona w czasie rzeczywistym. Jest to odizolowany proces lub grupa procesów, które posiadają własny system plików i przestrzeń sieciową, odseparowaną od reszty systemu.
    \item \textbf{Silnik} (\english{Docker Engine}) -- usługa systemowa środowiska uruchomieniowego odpowiedzialnego za budowanie i obsługę cyklu życia kontenerów.
\end{itemize}

Wykorzystanie platformy Docker w projekcie zapewnia spójność środowiska pomiędzy etapem deweloperskim, testowym i produkcyjnym, eliminując problem różnic w konfiguracji bibliotek systemowych.

\subsection{Infrastruktura jako kod}

Podejście \textit{Infrastruktura jako kod} (\english{Infrastructure as Code}, \akronim{IaC})\cite{TODO} polega na zarządzaniu infrastrukturą informatyczną (serwerami, sieciami) za pomocą plików konfiguracyjnych, zamiast ręcznej konfiguracji poprzez interfejsy graficzne czy jednorazowe skrypty. Pozwala to na wersjonowanie infrastruktury, łatwe powielanie środowisk oraz automatyzację wdrażania. W projekcie wykorzystano dwa komplementarne narzędzia realizujące ten paradygmat: \textit{Terraform}\cite{TODO} oraz \textit{Ansible}\cite{TODO}.

\subsection{Terraform -- powoływanie infrastruktury}

\textit{Terraform} to narzędzie służące do bezpiecznego i efektywnego tworzenia, zmieniania oraz wersjonowania infrastruktury. Działa w modelu deklaratywnym, co oznacza, że użytkownik definiuje w kodzie stan docelowy infrastruktury (np. jedną maszynę wirtualną i regułę zapory sieciowej), a narzędzie samodzielnie ustala kolejność operacji niezbędnych do osiągnięcia tego stanu.

Kluczową cechą \textit{Terraform} jest wykorzystanie interfejsów programistycznych dostawców usług chmurowych w celu powoływania zasobów. Deklaracja sprzętowa może opisywać jednocześnie wielu dostawców dzięki systemowi wtyczek w jednym, spójnym, dziedzinowym języku konfiguracyjnym. \textit{Terraform} powiela informacje o aktualnym stanie infrastruktury w pliku stanu, co pozwala na śledzenie zmian, planowanie aktualizacji zasobów i zapobiega nieplanowanym rekonstrukcjom stanu od zera.

\subsection{Ansible -- zarządzanie konfiguracją}

O ile \textit{Terraform} służy głównie do powoływania zasobów (tworzenia serwerów), o tyle \textit{Ansible} jest narzędziem do zarządzania konfiguracją i automatyzacji zadań na już istniejących maszynach. Pozwala na instalację oprogramowania, edycję plików konfiguracyjnych oraz zarządzanie usługami systemowymi.

\textit{Ansible} wyróżnia się architekturą bezagentową. Oznacza to, że na zarządzanych serwerach nie jest wymagana instalacja żadnego dodatkowego oprogramowania klienckiego. Komunikacja odbywa się z wykorzystaniem standardowego protokołu SSH (w systemach Linux). Scenariusze automatyzacji, zwane \textit{playbooks}, zapisywane są w formacie YAML.

Istotną cechą \textit{Ansible} jest idempotentność operacji. Oznacza to, że wielokrotne wykonanie tego samego scenariusza konfiguracji nie spowoduje błędów ani niepożądanych zmian, jeśli system znajduje się już w oczekiwanym stanie. Gwarantuje to stabilność i przewidywalność procesu wdrożenia aplikacji.

\subsection{GitHub Actions -- automatyzacja procesów}

\textit{GitHub Actions}\cite{TODO} to platforma do ciągłej integracji i ciągłego dostarczania (\english{Continuous Integration / Continuous Delivery}, \akronim{CI/CD}), zintegrowana bezpośrednio z systemem kontroli wersji \textit{GitHub}\cite{TODO}. Umożliwia ona definiowanie przepływów pracy w formacie YAML, które są automatycznie uruchamiane w odpowiedzi na określone zdarzenia w repozytorium, takie jak wypchnięcie kodu, otwarcie zgłoszenia czy utworzenie nowego wydania.

Architektura \textit{GitHub Actions} opiera się na koncepcji wykonawców (\english{runner}) -- maszyn wirtualnych lub kontenerów, na których wykonywane są zdefiniowane zadania. W projekcie wykorzystano udostępniane przez \textit{GitHub} współdzielone maszyny z systemem operacyjnym \textit{Ubuntu}, co eliminuje konieczność utrzymywania własnej infrastruktury do budowania aplikacji. Platforma ta oferuje bogaty ekosystem gotowych akcji (\english{actions}), które można wykorzystać jako modularne bloki budulcowe do tworzenia złożonych potoków wdrażania, obejmujących kompilację kodu, testowanie, budowanie obrazów kontenerowych oraz interakcję z chmurą obliczeniową.

\section{Konteneryzacja i proces budowania}

Aby zapewnić niezawodność procesu wytwarzania oprogramowania (\english{software supply chain}) oraz bezpieczeństwo wdrożenia, w projekcie wykorzystano technologię konteneryzacji. Podejście to gwarantuje spójność środowiska uruchomieniowego niezależnie od infrastruktury docelowej. Projekt składa się z monorepozytorium (TypeScript) oraz dedykowanej usługi klasyfikatora (Python). Ze względu na oddzielną architekturę projektu klasyfikatora zaimplementowaną w języku \textit{Python} zdecydowano się na rozdzielenie repozytoriów kodu. W obu przypadkach zastosowano strategie budowania obrazów zoptymalizowane pod kątem redukcji rozmiaru artefaktów oraz powierzchni ataku.

\begin{figure}[t]
\centering\includegraphics[width=\textwidth]{figures/repozytorium-zaleznosci-budowanie.png}
\caption{Struktura repozytorium kodu, uproszczony diagram zależności oraz tworzenia paczki dystrybucyjnej}\label{rys:repozytorium-zaleznosci-budowanie}
\end{figure}

W celu uniknięcia przedostania się kodu źródłowego, narzędzi deweloperskich oraz zbędnych zależności do środowiska produkcyjnego, w całym projekcie zastosowano mechanizm wieloetapowego budowania. Konfiguracja obrazów \textit{Docker} dla monorepozytorium (frontend i backend) zdefiniowana dzieli proces na cztery logiczne etapy:

\begin{enumerate}
    \item \textbf{Etap kompilacji}: Wykorzystuje pełny obraz środowiska \textit{Node.js}\cite{TODO} -- środowiska uruchomieniowego kodu \textit{JavaScript}. W tym kroku następuje instalacja wszystkich zależności (w szczególności deweloperskich) z użyciem programu \textit{npm}\cite{TODO}, budowanie aplikacji i kompilacja kodu.
    \item \textbf{Etap przygotowania zależności backendu}: Ponownie obraz środowiska \textit{Node.js}, gdzie instalowane są wyłącznie biblioteki wymagane do działania backendu, lecz z pominięciem narzędzi deweloperskich. Redukuje to wektor ataku w finalnym obrazie (m.in. liczbę potencjalnych podatności i zagrożeń).
    \item \textbf{Etap scalania dla frontendu}: Finalny obraz ze statycznymi plikami aplikacji frontendu bazujący na uproszczonym obrazie serwera HTTP \textit{Nginx}\cite{TODO}. Obraz skonfigurowano pod aplikację jednostronicową i progresywną aplikację internetową. Wymagane przez aplikację zależności do działania po stronie klienta są zapewniane w procesie budowy z paczką dystrybucji. Oznacza to przekopiowanie zależności do paczki lub utworzenie odnośników do pobrania paczek z sieci dostarczania zawartości (\english{Content Delivery Network}, \akronim{CDN})\cite{TODO}. 
    \item \textbf{Etap scalania dla backendu}: Finalny obraz uruchamiający serwer backendu rozszerzający uproszczony obraz środowiska \textit{Node.js} o skompilowany kod z pierwszej i pliki zależności z drugiej warstwy.
\end{enumerate}

W procesie wykorzystano nowoczesny mechanizm buforowania (\english{cache}) dostępny w silniku budowania \textit{Docker BuildKit}. Pozwala on na przechowywanie pobranych pakietów menedżera zależności pomiędzy kolejnymi uruchomieniami potoku przetwarzania, co redukuje ruch sieciowy i przyspiesza proces.

Moduł klasyfikatora intencji, napisany w języku Python, wymagał odrębnego podejścia do procesu budowania. Ze względu na specyfikę środowiska Python oraz konieczność obsługi dużych bibliotek numerycznych i uczenia maszynowego (takich jak \textit{scikit-learn}, \textit{sentence-transformers}, \textit{numpy}) wykorzystano menedżer pakietów \textit{uv}\cite{TODO}. Zastosowana strategia budowania obrazu \textit{Docker} opiera się na zaleceniach z dokumentacji \textit{uv} i korzysta m.in. z dedykowanego obrazu z preinstalowanym narzędziem \textit{uv} i interpreterem języka \textit{Python}, pomija zależności deweloperskie, wymusza kompilację plików źródłowych Python do kodu bajtowego (.pyc), wstępnie przetwarza i weryfikuje zbiór danych do działania modelu.

\section{Automatyzacja procesów ciągłej integracji i dostarczania}

Proces ciągłej integracji i dostarczania (\english{Continuous Integration / Continuous Delivery}, CI/CD) został w pełni zautomatyzowany z wykorzystaniem platformy \textit{GitHub Actions}. Potok przetwarzania jest uruchamiany automatycznie przy każdym wypchnięciu zmian do gałęzi głównej (\texttt{main}) lub utworzeniu tagu wersji (np. \texttt{v1.0.0}).

Kluczowym aspektem wdrożonego potoku jest jego optymalizacja pod kątem czasu wykonania oraz bezpieczeństwa łańcucha dostaw. Składa się on z następujących, sekwencyjnie wykonywanych kroków:

\begin{enumerate}
    \item \textbf{Inicjalizacja środowiska}: Konfiguracja narzędzia \textit{Cosign}\cite{TODO} (do podpisywania obrazów \textit{Docker}) oraz \textit{Docker Buildx} (silnika budowania obrazów \textit{Docker} obsługującego zaawansowany mechanizm buforowania pakietów).
    \item \textbf{Uwierzytelnienie}: Logowanie do rejestru obrazów \textit{Docker} -- \textit{GitHub Container Registry} przy użyciu jednorazowego tokenu generowanego przez GitHub dla czasu trwania zadania.
    \item \textbf{Zarządzanie pamięcią podręczną}: W celu przyspieszenia instalacji zależności w kontenerach, zastosowano akcję \texttt{reproducible-containers/buildkit-cache-dance}. Pozwala ona na wstrzyknięcie pamięci podręcznej z systemu plików \textit{GitHub Actions} bezpośrednio do warstw budowania \textit{Docker BuildKit}. Dzięki temu, jeśli pliki definiujące zależności (np. \texttt{package-lock.json}) nie uległy zmianie, Docker nie musi ponownie pakietów z internetu, lecz korzysta z lokalnej kopii.
    \item \textbf{Równoległe budowanie (Docker Bake)}: Zamiast sekwencyjnego budowania poszczególnych obrazów, wykorzystano moduł silinka \textit{Docker Buildx} -- \textit{Docker Bake}. Pozwala on na zdefiniowanie grup celów (backend, frontend) i ich równoległe budowanie, co skraca całkowity czas operacji. Akcja automatycznie zarządza tagowaniem obrazów oraz przesyłaniem ich do rejestru \textit{GitHub Container Registry}.
    \item \textbf{Kryptograficzne podpisywanie obrazów}: Każdy zbudowany i przesłany obraz \textit{Docker} jest podpisywany cyfrowo przy użyciu narzędzia \textit{Cosign} w trybie \textit{keyless}. Korzysta on z tymczasowej tożsamości (aktywnej tylko w trakcie działania potoku i dostępnej tylko wewnątrz środowiska GitHub Actions) do wygenerowania ulotnego certyfikatu do podpisu. Dzięki temu, w rejestrze publicznym (\textit{Rekor transparency log})\cite{TODO} odkładany jest dowód, że dany obraz (identyfikowany przez skrót \textit{SHA}) został zbudowany na podstawie precyzyjnej wersji kodu źródłowego w jawnie zdefiniowanym środowisku \textit{Github Actions}, co zabezpiecza przed atakami typu \textit{Supply Chain}.
\end{enumerate}

\begin{figure}[t]
\centering\includegraphics[width=\textwidth]{figures/diagram-wdrozenia.png}
\caption{Diagram wdrożenia z użyciem Terraform i Ansible}\label{rys:diagram-wdrozenia}
\end{figure}

Infrastruktura chrmurowa jest definiowana w kodzie (\english{Infrastructure as Code}, IaC) z wykorzystaniem narzędzi Terraform (do powoływania zasobów chmurowych) oraz Ansible (do konfiguracji serwera), co przedstawiono na Rysunku \ref{rys:diagram-wdrozenia}.

Dzięki oddelegowaniu części przetwarzania wymagającej zasobowo do zewnętrznych usług (np. filtrowania ruchu i uruchomienia dużych modeli językowych), to pozostałe komponenty systemu ograniczone żądaniach zasobów z powodzeniem mieszczą się na pojedynczej instancji maszyny wirtualnej typu \texttt{e2-micro} (2 vCPU, 1 GB pamięci) dostępnej w ramach platformy Google Cloud\cite{TODO}. W celu ułatwienia procesu wdrożenia wykorzystano platformę konteneryzacji Docker. Graficzną reprezentację układu wykorzystywanych usług przedstawiono na Rysunku \ref{rys:architektura-sieciowa}.

Proces wdrażania zmian w infrastrukturze i aplikacji podzielony jest na trzy uzupełniające się warstwy:

\begin{enumerate}
    \item \textbf{Infrastruktura chmurowa (Terraform)}: Warstwa ta definiuje zasoby w chmurze \textit{Google Cloud Platform}. Skrypty \textit{Terraform} uruchamiane z lokalnej maszyny deweloperskiej odpowiadają za powołanie instancji maszyny wirtualnej i zewnętrznych partycji dysków trwałych, rezerwację statycznych adresów IP, konfigurację zapory sieciowej, otwierając jedynie niezbędne porty dla ruchu przychodzącego i zasobników magazynu obiektowego do zdjęć wraz z regułami dostępu oraz kontem usługi.
    
    \item \textbf{Konfiguracja systemu operacyjnego (Ansible)}: Po powołaniu infrastruktury, narzędzie \textit{Ansible} jest wykorzystywane do wstępnej konfiguracji serwera. Skrypty te, również uruchamiane doraźnie (podczas pierwszej konfiguracji systemu), instalują środowisko uruchomieniowe \textit{Docker}, konfigurują zewnętrzne dyski trwałe (dedykowane osobno dla danych bazy danych i osobno dla kopii zapasowych w celu zapewnienia odpowiedniej wydajności i separacji awarii) oraz konfigurują narzędzie \textit{Borgmatic}\cite{TODO} do automatycznego tworzenia szyfrowanych kopii zapasowych bazy danych (działające poza środowiskiem Docker ze względu na ograniczenia tej technologii do uruchamiania zadań okresowych).
    
    \item \textbf{Wdrażanie aplikacji (Ansible w CI/CD)}: Bieżące aktualizacje kodu aplikacji są obsługiwane przez automatyczne przepływy pracy w \textit{GitHub Actions}. Przepływ pracy po wypchnięciu zmian do repozytorium kontroli wersji uruchamia zestaw zadań, który bezpiecznie kopiuje pliki konfiguracyjne \textit{Docker Compose} definiujące uruchomienie kontenerów na serwer oraz zmienne środowiskowe (takie jak hasła do bazy danych czy klucze API) pobrane z bezpiecznego magazynu sekretów \textit{GitHub Secrets} bezpośrednio do pliku \texttt{.env} na serwerze. Następnie \textit{Ansible} wykonuje polecenia restartu kontenerów, co powoduje pobranie najnowszych obrazów i uruchomienie zaktualizowanej wersji aplikacji. Proces ten jest rozdzielony na niezależne przepływy dla głównej aplikacji, klasyfikatora NLP oraz warstwy bazy danych i proxy, co pozwala na niezależne aktualizacje komponentów. Dodatkowo, wszystkie kontenery działają w trybie automatycznego restartu, co przywraca dostępność usług w przypadku przejściowych awarii.
\end{enumerate}

\section{Mechanizmy bezpieczeństwa}

Wdrożenie systemu zrealizowano zgodnie ze strategią obrony w głąb, implementując wielowarstwowe mechanizmy zabezpieczeń obejmujące łańcuch dostaw, infrastrukturę sieciową, środowisko uruchomieniowe oraz warstwę aplikacji.

\subsection{Bezpieczeństwo infrastruktury sieciowej}

Ochrona serwera i kontenerów opiera się na minimalizacji powierzchni ataku:

\begin{itemize}

    \item \textbf{Ochrona sieciowa (Cloudflare i Firewall)}: Punktem wejścia do systemu jest usługa \textit{Cloudflare}\cite{TODO}, pełniąca funkcję zapory sieciowej aplikacji (\english{Web Application Firewall}, \akronim{WAF}) oraz serwera nazw domen (\english{Domain Name System}, \akronim{DNS}). Ukrywa ona rzeczywisty adres IP serwera i filtruje złośliwy ruch. Zapora sieciowa \textit{Google Cloud} dodatkowo ogranicza ruch przychodzący do serwera wyłącznie do protokołów HTTPS i SSH.
    \item \textbf{Odwrotny pośrednik (Traefik)}: Bezpośrednio na serwerze ruchem zarządza odwrotne proxy (\english{reverse proxy}) \textit{Traefik}\cite{TODO}. Jest on skonfigurowany jako jedyny punkt styku udostępnionych aplikacji z siecią zewnętrzną, obsługując wyłącznie ruch szyfrowany na porcie \texttt{443} -- po protokole HTTPS. Certyfikaty TLS są zapewniane dzięki bezpłatnej usłudze zautomatyzowanego i otwartego urzędu certyfikacji \textit{Lets's Encrypt}\cite{TODO} udostępnianej przez organizację non-profit Internet Security Research Group (\akronim{ISRG}). \textit{Traefik} automatycznie zarządza cyklem życia certyfikatów TLS, wykorzystując mechanizm wyzwań DNS (\english{DNS challenge}) w integracji z API \textit{Cloudflare}. Użycie tego mechanizmu pozwala na uzyskanie zaufanych certyfikatów z usługi \textit{Let's Encrypt} bez ujawniania publicznie powiązania zewnętrznego adresu IP serwera aplikacji z nazwą domenową (wszystkie żądania certyfikatów są zapisywane w publicznym rejestrze, a inne mechanizmy wyzwań służących potwierdzeniu autentyczności żądania wymagają bezpośredniego ruchu po nazwie domenowej do serwera z Internetu).
    \item \textbf{Izolowane sieci wirtualne}:  Separacja komponentów systemu została zrealizowana poprzez izolowane sieci wirtualne wewnątrz środowiska \textit{Docker}. Kontener bazy danych PostgreSQL nie udostępnia żadnych portów na zewnątrz hosta i jest dostępny wyłącznie dla kontenera backendu poprzez dedykowaną sieć wewnętrzną. Taka konfiguracja uniemożliwia bezpośredni dostęp do danych z poziomu Internetu, nawet w przypadku błędnej konfiguracji zapory ogniowej.
\end{itemize}

\subsection{Bezpieczeństwo aplikacji i środowiska uruchomieniowego}

Na poziomie kodu aplikacji wdrożono mechanizmy zapobiegające błędom logicznym i wstrzyknięciom:

\begin{itemize}
    \item \textbf{Walidacja danych (Zod)}: Wszystkie dane wejściowe trafiające do API są rygorystycznie weryfikowane przy użyciu biblioteki \textit{Zod} pod kątem zgodności ze zdefiniowanym schematem. Zapobiega to przetwarzaniu nieprawidłowych lub złośliwych struktur danych.
    \item \textbf{Architektura modułowa}: Podział systemu na niezależne kontenery (frontend, backend, klasyfikator, baza danych) odseparowane wirtualnymi sieciami \textit{Docker} ogranicza zasięg ewentualnego ataku. Kompromitacja jednego elementu (np. klasyfikatora) nie zapewnia dostępu do innych komponentów (np. do bazy danych, która akceptuje połączenia tylko z sieci wewnętrznej).
    \item \textbf{Dodatkowo zabezpieczone obrazy kontenerów}: Aplikacje uruchamiane są w oparciu o obrazy, takie jak \textit{Google Distroless Node.js}\cite{TODO} (dla backendu) czy \textit{Chainguard Nginx} (dla frontendu). Obrazy te są pozbawione powłoki systemowej (shell) oraz zbędnych narzędzi, co drastycznie utrudnia atakującemu wykonanie złośliwego kodu w przypadku przełamania zabezpieczeń aplikacji.
    \item \textbf{Zasada najmniejszych przywilejów}: Kontenery są skonfigurowane do pracy bez uprawnień administratora (\english{root}), wykorzystując dedykowanych użytkowników systemowych. Zapobiega to eskalacji uprawnień na system gospodarza w przypadku ucieczki z kontenera.
\end{itemize}

\subsection{Bezpieczeństwo łańcucha dostaw}

Istotnym elementem bezpieczeństwa nowoczesnych systemów jest ochrona procesu wytwarzania oprogramowania (\english{Software Supply Chain Security}). W projekcie zastosowano szereg mechanizmów gwarantujących integralność i pochodzenie kodu:

\begin{itemize}
    \item \textbf{Podpisywanie obrazów (Cosign i Rekor)}: Wszystkie obrazy \textit{Docker} generowane w procesie CI/CD są kryptograficznie podpisywane przy użyciu narzędzia \textit{Cosign} w trybie \textit{keyless}\cite{TODO}. Mechanizm ten wykorzystuje protokół \textit{OpenID Connect} (OIDC) do uwierzytelnienia tożsamości procesu \textit{GitHub Actions} w urzędzie certyfikacji \textit{Fulcio}, który wydaje krótkotrwały certyfikat cyfrowy. Podpisany skrót obrazu jest następnie rejestrowany w publicznym, niemodyfikowalnym logu transparentności \textit{Rekor}. Umożliwia to późniejszą weryfikację, że dany obraz został zbudowany z konkretnej, precyzyjnej wersji kodu źródłowego w zaufanym środowisku wykonawczym, uniemożliwiając podstawienie złośliwego artefaktu przez osoby trzecie.

    \item \textbf{Automatyzacja aktualizacji (Dependabot)}: W repozytorium skonfigurowano narzędzie \textit{Dependabot}\cite{TODO}, które okresowo monitoruje zależności projektu pod kątem znanych podatności (CVE). W przypadku wykrycia luki bezpieczeństwa w używanej bibliotece system automatycznie generuje zgłoszenie z aktualizacją do bezpiecznej wersji, co pozwala na szybką reakcję na nowe zagrożenia.

    \item \textbf{Precyzyjne wersjonowanie zależności}: Aby zagwarantować powtarzalność procesu budowania (\english{reproducible builds}) i ochronę przed atakami na łańcuch dostaw, zastosowano precyzyjne wersje bibliotek. W projekcie wykorzystano pliki \texttt{package-lock.json} (dla ekosystemu \textit{Node.js}) oraz \texttt{uv.lock} (dla środowiska \textit{Python}), które zawierają sumy kontrolne konkretnych wersji pakietów. Gwarantuje to instalację identycznego kodu na każdym środowisku. Dodatkowo, w definicjach przepływów pracy \textit{GitHub Actions}, odwołania do zewnętrznych akcji realizowane są poprzez unikalny skrót SHA identyfikujący zmianę (np. \texttt{actions/checkout@a5ac7...}), zamiast modyfikowalnych tagów wersji, co eliminuje ryzyko wykonania złośliwego kodu w przypadku przejęcia repozytorium dostawcy akcji.
\end{itemize}


% TODO: podsumownie rozdziału
