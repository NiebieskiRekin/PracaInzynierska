\chapter{Architektura systemu}

\section{Założenia projektowe}

System \definicja{Moje Konie} został zaprojektowany z myślą o zapewnieniu pełnej kontroli nad zarządzaniem stajnią oraz umożliwieniu użytkownikom wygodnego monitorowania stanu i historii koni w hodowli. 

Po zalogowaniu użytkownik otrzymuje dostęp do przeglądania pełnej listy swoich koni, zawierających zdjęcie oraz nazwę konia. Wyświetlanie listy jest responsywne: na większych ekranach stosowane są trzy kolumny, natomiast na urządzeniach mobilnych tylko jedna. Lista koni wyposażona jest w wyszukiwarkę, pozwalającą na filtrowanie po nazwie poprzez wyszukanie fragmentu tekstu. Każda karta konia umożliwia przejście do ekranu ze szczegółowymi informacjami, gdzie użytkownik może zobaczyć numer przyżyciowy, numer chipa, rocznik urodzenia, rodzaj, płeć, datę przybycia i odejścia ze stajni, a także najnowsze aktywne wydarzenia związane z danym koniem, takie jak podkucia, szczepienia, odrobaczanie, podanie suplementów czy wizyty dentystyczne. Wymieniony numer przyżyciowy to unikalny kod nadawany koniowi, zapisany w jego paszporcie, który wraz z numerem transpondera (chipa) i danymi właściciela służy do jego pełnej identyfikacji, zapobiegając nielegalnemu obrotowi, a także umożliwia śledzenie zdrowia, szczepień i pochodzenia.

Na poziomie nawigacji system udostępnia moduły funkcjonalne obejmujące: zarządzanie końmi, weterynarzami, kowalami, wydarzeniami w stajni, asystentem oraz ustawieniami. Przy dodawaniu zdarzenia użytkownik wybiera jego typ, uzupełnia wymagane pola oraz wskazuje listę koni, do których zdarzenie ma zastosowanie. W celu wygodnej selekcji dostępny jest również przycisk pozwalający zaznaczyć wszystkie konie w danej stadninie. System podpowiada użytkownikowi powiązanych weterynarzy lub kowali przy dodawaniu zdarzeń wymagających ich udziału. Pod ostatnimi wydarzeniami znajduje się panel umożliwiający szybkie dodanie nowych wydarzeń, odpowiednio pogrupowanych według kategorii.

Dodatkowo użytkownik ma możliwość generowania raportów dla poszczególnych koni, w tym wyboru podzbioru wydarzeń oraz określenia zakresu czasowego według daty zdarzenia. System wysyła powiadomienia o zbliżającym się upływie ważności podkucia lub zdarzenia profilaktycznego. Użytkownik może określić preferencje powiadomień, w tym czas wyprzedzenia (w dniach i godzinach) oraz sposób doręczenia wiadomości (np. e-mail).

System pozwala na zarządzanie zdjęciami koni -- użytkownik może dodawać wiele zdjęć do jednego konia, a przełączanie między zdjęciami odbywa się za pomocą strzałek na ekranie szczegółów. Operacje dodawania i edycji koni odbywają się poprzez dedykowane formularze walidujące wymagane pola, natomiast usuwanie wymaga potwierdzenia ze strony użytkownika.

Podstawowym mechanizmem zabezpieczającym dostęp jest proces logowania, w którym użytkownik uwierzytelnia się przy użyciu adresu e-mail oraz hasła. Po poprawnym uwierzytelnieniu użytkownik uzyskuje autoryzację do wykonywania działań na obiektach przypisanych do jego hodowli. System zapewnia możliwość zmiany hasła przez użytkownika po podaniu aktualnego hasła i dwukrotnym wprowadzeniu nowego hasła. Treść hasła jest domyślnie maskowana, a użytkownik ma możliwość wyświetlenia tekstu jawnego podczas wpisywania. W przypadku podania nieprawidłowych danych uwierzytelniających system wyświetla odpowiedni komunikat o błędzie.

Projektując system, zwrócono szczególną uwagę na bezpieczeństwo, modularność oraz skalowalność. Dane uwierzytelniające przechowywane są w formie bezpiecznych skrótów (\english{hash}) uniemożliwiających odtworzenie pierwotnego hasła. System jest w stanie obsłużyć łącznie 400 użytkowników, w tym do 100 jednoczesnych sesji. Interfejs użytkownika został zaprojektowany w sposób intuicyjny i wygodny, działający zarówno w przeglądarce internetowej, jak i na urządzeniach mobilnych. Koszt utrzymania systemu jest minimalny, a administracja systemem prosta, co zwiększa długoterminową trwałość i niezawodność rozwiązania.

Wszystkie te cechy łącznie pozwalają na zapewnienie wysokiego poziomu bezpieczeństwa danych, przejrzystej organizacji informacji oraz wygodnej obsługi codziennych czynności w hodowli koni.

\section{Opis architektury aplikacji}

Ze względu na specyfikę aplikacji umożliwiającą edycję danych dotyczących danej hodowli koni wielu użytkownikom, w szczególności korzystających w większości z urządzeń mobilnych oraz sporadycznie z komputerów osobistych, zdecydowano się na formę systemu webowego z przeglądarkowym interfejsem użytkownika. Aplikacje internetowe pozwalają na wykorzystanie bogatego i dojrzałego zaplecza technologicznego do wyświetlania stron internetowych, co znacząco upraszcza aspekt dystrybucji oprogramowania oraz współbieżnego dostępu do danych.

Dla zachowania kompatybilności z technologią progresywnych aplikacji internetowych oraz modularności zdecydowano się na rozdzielenie warstwy przetwarzania logiki biznesowej z dostępem do danych, z którą użytkownik nie wchodzi w bezpośrednią interakcję -- nazywaną backend, od warstwy bezpośrednio obsługującej interfejs użytkownika i wizualną prezentację danych -- frontend. Użytkownik inicjuje wszelkie interakcje z obydwoma komponentami, choć zapytania do backendu są inicjowane w przeglądarce użytkownika wchodzącego w interakcję z frontendem, a także otrzymane dane i komunikaty diagnostyczne są wyłącznie obsługiwane przez ten komponent. Zapytania sieciowe służące pobraniu i aktualizacji danych inicjowane są poprzez moduł frontendu wykonywany w przeglądarce użytkownika odbywają się na warstwie 7 modelu ISO/OSI (warstwie aplikacji) za pomocą protokołu HTTPS. Z perspektywy działania serwera frontend obsługuje żądania zwracając pliki HTML, CSS i JavaScript, natomiast backend działa w bezstanowej architekturze sieciowego interfejsu programowania REST zwracającego dane w formacie serializacji JSON. 

% Architektura sieciowa i routing (Network & Routing)
% Opis przepływu ruchu na podstawie diagramu 2 (Architektura sieciowa).
%     Reverse Proxy i Edge: Rola Traefik jako punktu wejścia (Ingress). Automatyczne zarządzanie certyfikatami TLS (Let's Encrypt).
%     DNS i ochrona brzegowa: Wykorzystanie Cloudflare jako pierwszej linii obrony (WAF, maskowanie IP serwera, DNS).
%     Komunikacja wewnętrzna: Jak kontenery rozmawiają ze sobą wewnątrz prywatnej sieci Dockera, bez wystawiania ich bezpośrednio do Internetu.

% Model wdrożenia: Wykorzystanie Google Cloud Platform (GCP) – instancja Compute Engine.

\section{Frontend}

Korzystając z technologii progresywnych aplikacji internetowych (\english{Progressive Web App}, \akronim{PWA}) oraz praktyki responsywnego projektowania stron internetowych (\english{responsive web design}, \akronim{RWD}) zaimplementowano spójny interfejs użytkownika dla platform mobilnych. Do implementacji technologii progresywnych aplikacji internetowych wymagane jest, aby interfejs graficzny użytkownika był skomponowany w zdecydowanej większości ze statycznych dokumentów hipertekstowych HTML (HyperText Markup Language), arkuszy stylów CSS (Cascading Style Sheets) oraz kodu w języku programowania JavaScript. Statyczne pliki w podanym kontekście oznaczają podleganie nieczęstym zmianom poprzez pobranie zaktualizowanej wersji z serwera -- wyłącznie między oddzielnymi wydaniami aplikacji i nigdy w celu wyświetlenia nowych danych.

Interaktywna prezentacja danych jest możliwa natomiast poprzez zmianę struktury wyświetlanego dokumentu hipertekstowego wykonywaną po stronie klienta z użyciem kodu JavaScript w przeglądarce. Wymienione działanie jest wykonywane poprzez interfejs programowania Document Object Model (DOM, pl. \textit{Model Obiektowy Dokumentu}) pozwalający na częściową lub pełną modyfikację dowolnego węzła (np. akapitu tekstu, separatora, kontrolek, obiektu multimedialnego) w hierarchicznej strukturze drzewa dokumentu HTML. Interfejs ten jest w praktyce wykorzystywany przez bibliotekę React, która nieco modyfikuje model z dokumentów HTML i skryptów JavaScript na komponenty wielokrotnego użytku (zawierające wymagane fragmenty dokumentu HTML i funkcje JavaScript) budujące deklaratywne widoki (strony internetowe). Komponenty można powiązać z danymi, czyli zaprojektować ich wygląd w celu prezentacji danych zgodnie z ich schematem oraz skonfigurować ich źródło, które będzie automatycznie odświeżane, dążąc do zadeklarowanego stanu. Komponenty można w sobie zagnieżdżać, odtwarzając te same aspekty hierarchicznej struktury, a ich zmiany są śledzone poprzez użycie wewnętrznej dla tej biblioteki kopii Modelu Obiektowego Dokumentu nazywanego Virtual DOM (pl. Wirtualny Model Obiektowy Dokumentu).

Opisane podejście nazywa się \textit{aplikacją jednostronicową} (\english{Single-page application}, \akronim{SPA}), co wynika głównie ze sposobu aktualizowania interfejsu na podstawie zmian w danych poprzez kod po stronie klienta i przesyłania statycznych dokumentów HTML, pomijając jednocześnie aspekt użycia wielu stron. W przypadku prezentowanej pracy rama projektowa (\english{framework}) została dostarczona przez bibliotekę React Router, która dostarcza narzędzie budujące (\english{build tool}) do aplikacji jednostronicowej, dostarczając ponadto zestaw narzędzi służących do przechodzenia pomiędzy osobnymi widokami w zależności od użytego adresu URL -- nazwany router, a także moduły do efektywnego pobierania danych w tle za pomocą funkcji asynchronicznych.


\section{Backend}

Przetwarzanie wykonywane po stronie serwera jest realizowane w znacznej części przez komponent backendu. Został on zaimplementowany jako bezstanowy interfejs programowania REST, który obsługuje komunikację za pomocą danych serializowanych do formatu JSON. Integruje on między sobą wiele komponentów, co zostało pokazane na diagramie architektury sieciowej, przedstawionym na Rysunku \ref{rys:architektura-sieciowa}. Jego głównym zadaniem jest udostępnienie dostępu do danych zapisanych w bazie danych przez protokół HTTP interfejsu sieciowego na warstwie 7 modelu ISO/OSI.

\begin{figure}[t]
\centering\includegraphics[width=\textwidth]{figures/architektura-sieciowa}
\caption{Architektura sieciowa aplikacji}\label{rys:architektura-sieciowa}
\end{figure}

Rola serwera HTTP jest spełniana przez framework \textit{Hono}. Framework ten pozwala na bardzo modularne tworzenie silnie typowanych endpointów, warstw pośrednich przetwarzania (\english{middleware}) i elastyczne łączenie ich w poszczególne ścieżki obsługiwane współbieżnie i wydajnie przez jeden z kilku dostępnych silników dopasowań (\english{router}).

Ze względu na wymóg współbieżnego, spójnego dostępu do danych o złożonych, ale stabilnych relacjach został wybrany system zarządzania relacyjną bazą danych \textit{PostgreSQL}. Spośród dostępnych na rynku rozwiązań wyróżnia się on brakiem opłat licencyjnych, bogatą dokumentacją, bardzo dobrą optymalizacją przetwarzania na małych i średnich zbiorach danych, obszernym zestawem funkcji, a także jest dobrze znana i lubiana przez zespół projektowy.

Zapytania do bazy danych są realizowane przez bibliotekę \textit{node-postgres}, która jest głównym silnikiem do tworzenia puli połączeń do bazy danych. Biblioteka ta jest rozszerzana przez bibliotekę \textit{DrizzleORM} w celu utworzenia odwzorowania obiektowo-relacyjnego (\akronim{ORM}, \english{Object-Relational mapping}) struktur obiektów utworzonych w języku TypeScript na relacje bazy danych w języku SQL, napisania zoptymalizowanych zapytań do bazy danych, utworzenia migracji pomiędzy wersjami schematu tabel w procesie tworzenia aplikacji i jej wdrożenia, a także wypełniania bazy danych początkowymi danymi. Biblioteka \textit{DrizzleORM} charakteryzuje się zbliżoną składnią, co język SQL, dzięki czemu dobra znajomość tworzenia zapytań przez zespół premiowała dobrą optymalizacją przepływu danych i prostszym, wydajniejszym modelem abstrakcji -- każde poprawne zapytanie utworzone z użyciem \textit{DrizzleORM} jest konwertowane na dokładnie jedno zapytanie do bazy danych, a przygotowane wcześniej zapytania można było przepisać z małymi zmianami składni. Dzięki podejściu do połączenia z bazą danych z niewielką warstwą abstrakcji możliwe było wykorzystanie bardziej zaawansowanych funkcjonalności bazy danych PostgreSQL, takich jak m.in. użycie schematów jako dynamicznego zamiennika osobnych baz danych dla różnych, odseparowanych środowisk na tym samym serwerze, reprezentacja typów wyliczeniowych z użyciem \textit{pg\_enum} (m.in. do rodzajów koni i zdarzeń profilaktycznych), filtrowanie powiadomień do wysłania względem różnicy czasu wyliczanej po stronie silnika PostgreSQL, grupowanie kilku zapytań w jedno dzięki składni \textit{UNION} (wykorzystywane przy pobieraniu zdarzeń profilaktycznych) i podzapytaniom z klauzulami \textit{NOT EXISTS} (do znalezienia czy istnieje domyślne zdjęcie dla danego konia przy usuwaniu), \textit{PARTITION BY} (do znalezienia najnowszych aktywnych zdarzeń profilaktycznych z każdej kategorii dla danego konia).

\textit{DrizzleORM} jednocześnie dostarcza pełne interfejsy i typy danych oczekiwane przez język TypeScript, a nawet schematy walidacji do biblioteki walidacyjnej \textit{Zod}, dzięki dodatkowi \textit{drizzle-zod}. Pozwoliło to w procesie tworzenia aplikacji na zachowanie spójności w przepływie danych oraz zaoszczędzenie czasu na pisanie złożonych definicji schematów. Wykorzystanie biblioteki \textit{Zod} stanowi istotny element pracy, gdyż ze względu na zaawansowane i ergonomiczne funkcje walidacji, a także ogromną popularność biblioteka stała się standardem w środowisku TypeScript do tworzenia modeli danych. \textit{Zod} pozwala na zdefiniowanie schematów opisujących układ pól i ograniczenia danych, a następnie weryfikować wartości dowolnych, niesprawdzonych obiektów przyjmowanych przez program, aby przetransformować lub potwierdzić poprawność z założonym formatem danych. Cenną funkcją biblioteki \textit{Zod} jest zwracania szczegółowej, ustrukturyzowanej listy niezgodności ze schematem w trakcie walidacji. 

Zbiory powiązanych schematów można połączyć w rejestry, co pozwala powiązać je z dodatkowymi ustrukturyzowanymi metadanymi. Gotowe schematy można również obustronnie konwertować do formatu zgodnego ze specyfikacją JSON Schema, w tym OpenAPI. Wymieniona specyfikacja OpenAPI zapewnia spójny sposób przesyłania informacji na każdym etapie cyklu życia API. Jest to język specyfikacji dla interfejsów API HTTP, który definiuje strukturę i składnię w sposób niezależny od języka programowania, w którym utworzono API. Ekosystem narzędzi powiązany z tym rozwiązaniem jest bardzo bogaty i dostarcza wiele rozwiązań generujących w pełni zautomatyzowany sposób gotową implementację (zdefiniowanej części sieciowej) klienta bądź serwera dla danej specyfikacji. Specyfikacje te są pisane w formatach YAML lub JSON, co umożliwia łatwe udostępnianie i ich wykorzystanie.

Dzięki użyciu biblioteki \texttt{@hono/zod-validator} dla każdej końcówki API Hono zdefiniowano schemat oczekiwanych danych. Wykorzystanie funkcji \texttt{zValidator} z tej samej biblioteki umożliwiło automatyczną walidację zgodności danych wejściowych ze schematem. Elastyczność rozwiązania powoduje, że walidacja jest przeprowadzana niezależnie czy dane są przekazywane jako element ścieżki wyszukiwania (\english{query parameters}), dane JSON w ciele żądania, czy zgodnie z typem \texttt{multipart/form-data} bądź \texttt{application/form-data}. Dodatkowo zestaw powiązanych bibliotek \textit{hono-openapi} i \textit{@hono/zod-openapi} pozwolił na dodanie adnotacji do dokumentacji danej końcówki w formacie OpenAPI oraz zdefiniowanie schematu zwracanych danych w zależności od kodu odpowiedzi. Wygenerowana dokumentacja w uniwersalnym formacie OpenAPI z całego backendu posłużyła jako wzorzec do tworzenia zapytań przez Gemini w procesie przetwarzania intencji użytkownika. Również dzięki interfejsowi graficznemu dostarczanemu przez bibliotekę \textit{Scalar} do obsługi dokumentacji OpenAPI niewielkim nakładem pracy utworzono zaawansowany panel administracyjny do zarządzania użytkownikami i stadninami przez administratorów. Został on przedstawiony dokładniej w rozdziale \ref{sec:panel-administracyjny}: \nameref{sec:panel-administracyjny}. Schematy \textit{Zod} wykorzystywane są również do walidacji konfiguracji zmiennych środowiskowych wymaganych do poprawnego działania aplikacji. 

\subsection{Kontrola dostępu} \label{sec:kontrola-dostepu}

Aplikacja \definicja{Moje Konie} korzysta ze scentralizowanego, zintegrowanego z kodem aplikacji systemu uwierzytelniającego. W celu zapewnienia bezpiecznego systemu uwierzytelniającego skorzystano z zewnętrznej biblioteki \textit{BetterAuth}, która dostarczyła komponenty do zarządzania użytkownikami, kontami, hodowlami koni w kontekście organizacji i przynależnościami do nich. Biblioteka wykorzystuje PostgreSQL jako magazyn danych i tworzy automatycznie wymagane relacje poprzez integracje z DrizzleORM. Konta użytkowników mogą zostać tworzone wyłącznie przez użytkownika z grupy administratorów, nie jest możliwa rejestracja zewnętrzna bezpośrednio przez użytkownika. Uwierzytelnianie odbywa się wyłącznie za pomocą adresu e-mail i hasła, a adresy e-mail muszą zostać potwierdzone poprzez link. Użytkownicy mają możliwość zmiany ustawionego hasła, a po zakończeniu tego procesu następuje unieważnienie wszystkich aktywnych sesji, co powstrzymuje przed dostępem z potencjalnie przejętych urządzeń.

Zarządzanie sesjami realizowane jest poprzez mechanizm ciasteczek i zapisanie aktywnych sesji w bazie danych. W celu optymalizacji wydajności i redukcji obciążenia bazy danych przy sekwencyjnych żądaniach wykorzystano mechanizm pamięci podręcznej ciasteczek wynoszący 5 minut. Dzięki temu backend zamiast wypytywać bazę danych dla każdego przychodzącego żądania wymagającego uwierzytelnienia może potwierdzić daną sesję z ciasteczka podpisanego kryptograficznie. Takie ciasteczko trafia następnie do przeglądarki użytkownika. Podpisy i potwierdzenia są realizowane przez backend z użyciem tajnego symetrycznego klucza (wyłącznie po stronie serwera) z użyciem funkcji skrótu \emph{HMAC-SHA256}. Po upłynięciu ustalonego czasu wygaśnięcia pamięci podręcznej kolejne żądanie wymagające uwierzytelnienia będzie powodowało utworzenie zapytania do bazy danych o potwierdzenie sesji użytkownika i generowało nowe podpisane ciasteczko. Sesje użytkowników mają długi czas wygasania wynoszący 30 dni, w którego trakcie ważność sesji jest automatycznie odświeżana przy aktywności użytkownika raz na 24 godziny. Ma to na celu utrzymywanie poprawnej sesji (stanu bycia zalogowanym do strony) na czas dostatecznie długi, aby nie stanowił problemu dla aktywnych i powracających po niedługich odstępach czasu użytkowników. Długość ważności sesji jest podyktowana zarządzaniem danymi o nieczęstej zmienności i niską potrzebą codziennego pobierania danych przez użytkowników.

Pozostałe aspekty ciasteczek sesyjnych skonfigurowano z naciskiem na bezpieczeństwo. Flaga \emph{SameSite} ustawiona na \emph{Strict} wymusza pełną zgodność nazwy domenowej serwera, z którym następuje połączenie w odniesieniu do serwera, który ustawił dane ciasteczko, co pomaga zapobiegać atakom polegającym na wymuszaniu nieautoryzowanej akcji w przeglądarce ofiary takim jak \emph{Cross Site Request Forgery} (\akronim{CSRF}). Atrybut \emph{HttpOnly} zabrania dostępu do wartości danego ciasteczka sesji przez kod JavaScript w przeglądarce klienta, co ponownie zawęża możliwe ataki z użyciem złośliwych skryptów takie jak \emph{Cross Site Scripting} (\akronim{XSS}). Finalnie flagi \emph{Secure} oraz \emph{Partitioned} są skonfigurowane zgodnie z zaleceniami przeglądarek i wymuszają odpowiednio poufność przez konieczność stosowania protokołu HTTPS, oraz izolację sesji użytkownika zgodnie z wytycznymi prywatności.

Warstwa autoryzacji wykorzystuje model kontroli dostępu opartej na 2 rolach (admin, user) oraz strukturę wielodostępową (\english{multi-tenancy}) poprzez tworzenie organizacji do zarządzania odrębnymi hodowlami. Domyślna rola użytkownika pozwala na zarządzanie cyklem życia (dodawanie, usuwanie, edycja) wszystkich zwykłych obiektów takich jak: konie, wydarzenia z nimi związane, zapisani specjaliści, a także ustawienia użytkownika. Rola administratora jest przeznaczona dla osób posiadających odpowiednie kompetencje do zarządzania całą instancją serwera. Zatem pozwala na dodawanie nowych i edycję istniejących kont użytkowników, hodowli, danych uwierzytelniających oraz na wszystkie uprawnienia nadane podstawowej roli użytkownika. Dodatkowo włączono obsługę kluczy API. Są to jednoskładnikowe dane uwierzytelniające służące do obsługi żądań do backendu poprzez interfejsy programistyczne. Klucze te mogą być wykorzystywane do automatyzacji części procesów aplikacji z zewnętrznymi usługami, a także posłużyć jako składnik uwierzytelniający w panelu administracyjnym. Warstwa autoryzacji integruje się z serwerem utworzonym przez \textit{Hono} poprzez udostępnienie końcówek autoryzacyjnych pod ścieżką \texttt{/api/auth}. Zestaw dostępnych funkcji udostępnionych przez bibliotekę \textit{BetterAuth} jest dołączony do dokumentacji reszty backendu formacie OpenAPI. Dzięki wykorzystaniu gotowego zestawu tłumaczeń komunikaty błędów funkcji \textit{BetterAuth} zostały przetłumaczone na język polski. W celu poprawy widoczności informacji diagnostycznych o incydentach kluczowe zdarzenia bezpieczeństwa są rejestrowane.
\subsection{Baza danych}

Aplikacja posiada bogaty model danych, co ma swoje odniesienie w złożonym modelu encji związków przedstawionym na Rysunku \ref{rys:schemat-bazy-danych}. W celu zachowania jak najlepszej spójności zastosowano znormalizowaną postać bazy danych, a dla ułatwienia edycji głównego identyfikatora sztuczne klucze główne. Aplikacja została zaprojektowana z myślą, aby obsługiwać wiele oddzielnych hodowli na jednej instancji aplikacji w modelu architektury wielodostępowej (\english{multi-tenant}). Ze względu na to założenie wszystkie obiekty dodawane przez użytkowników muszą mieć powiązanie z daną hodowlą, której nadany identyfikator rozdziela przynależność do danego klienta -- dzierżawcy. Podstawową funkcjonalnością aplikacji jest zarządzanie końmi, w tym przypisanie im imion, nr paszportowych, istotnych dat, a także hodowli, do której należą i innych danych charakterystycznych. Dodatkowo dla każdego konia można przypisać dowolną liczbę zdjęć, których podstawowe dane o przynależności są zapisywane w bazie danych (do którego konia, czy dane zdjęcie jest domyślne), natomiast same pliki są zapisywane w oddzielnej usłudze zoptymalizowanej do przechowywania plików binarnych \emph{Google Cloud Storage} w danym zasobniku co zostało opisane dokładniej w rozdziale \ref{sec:gcs}: \nameref{sec:gcs}.

\begin{figure}[t]
\centering\includegraphics[width=\textwidth]{figures/schemat-bazy.png}
\caption{Schemat bazy danych}\label{rys:schemat-bazy-danych}
\end{figure}


Dla każdego konia można przypisać wiele wydarzeń takich jak podkucia, choroby, leczenia, rozrody czy zdarzenia profilaktyczne. W przypadku podkuć, leczeń, rozrodów i zdarzeń profilaktycznych przypisywany jest również specjalista -- kowal lub weterynarz, powiązany z danym wydarzeniem. W przypadku specjalistów przechowywane dane są proste i ograniczają się do wskazania imienia, nazwiska, numeru telefonu i hodowli, w jakiej zostali dodani. Do podkuć, chorób i zdarzeń profilaktycznych przypisane są daty zdarzenia/rozpoczęcia oraz ważności/zakończenia, a do wszystkich wydarzeń poza podkuciami również opisy. Zdarzenia profilaktyczne posiadają również pole wyboru rodzaju zdarzenia spośród: odrobaczania, podania suplementów, szczepienia, dentysty i inne. Natomiast wydarzenia -- rozrody dzielą się na: inseminację konia, sprawdzenie źrebności, wyźrebienie i inne. Istotna jest również możliwość powiązania leczeń do danej choroby konia. Utworzona bezpośrednio została również tabela \emph{notifications}, która przechowuje preferencje użytkownika dotyczące powiadamiania o zbliżającym się końcu ważności danego wydarzenia z konfigurowalną liczbą dni wyprzedzenia, godziną powiadomienia i metodą wysłania.

Pozostałe tabele zostały utworzone przez bibliotekę BetterAuth i służą do zarządzania użytkownikami i ich przynależnością do danej hodowli (organizacji), uwierzytelniania i kontroli dostępu. Tabela \emph{organization} przechowuje informacje o hodowli, w tym dostępną liczbą zapytań do wykorzystania przez moduł /definicja{Asystenta NLP}. Tabela \emph{member} reprezentuje relację wiele do wielu pomiędzy tabelami \emph{organization} a \emph{user}, co pozwala odszukać przynależność użytkownika do danej hodowli, a także sprawdzić rolę konta (administrator, konto zwykłe). Tabele \emph{account} i \emph{apikey} przechowują dane uwierzytelniające dla danego użytkownika, głównie wykorzystywane jest hasło do uwierzytelniania zwykłych kont, natomiast klucz API do dostępu administracyjnego. W tabeli \emph{session} odnajdziemy informacje o aktywnych sesjach logowania użytkowników. Tabela \emph{verification} przechowuje informacje o wysłanych e-mailach z potwierdzeniem po założeniu konta. Natomiast tabela \emph{invitation} nie jest w praktyce wykorzystywana w projekcie i dotyczy zaproszeń użytkowników do organizacji przez innych użytkowników aplikacji (w praktyce dane konto użytkownika jest wyłącznie dla jednej organizacji).

\section{Google Cloud Storage} \label{sec:gcs}

\textit{Google Cloud Storage} jest usługą oferowaną i zarządzaną przez firmę \textit{Google}, w ramach której otrzymujemy dostęp do magazynu obiektowego (\english{Object Storage}). Różni się on od tradycyjnego systemu plików (jak dysk twardy z drzewem katalogów) tym, że dane istnieją w płaskiej strukturze wewnątrz danego \textit{zasobnika}. Zasobnik jest wydzieloną częścią usługi przydzieloną do danego projektu i funkcjonuje jako kontener bez dalszej hierarchii. Zasobniki posiadają globalnie unikalne nazwy, są przypisane do określonego regionu geograficznego, a także definiują polityki dostępu. 

Dane zapisywane do zasobnika są reprezentowane jako \textit{obiekty}. Odpowiadają one plikom, takim jak zdjęcia czy dokumenty tekstowe, bez ograniczeń dotyczących wewnętrznej struktury danych -- każdy format jest akceptowalny. O ile usługa potrafi wyświetlać przesłane obiekty w formie przypominającej katalogi, to w rzeczywistości struktura jest płaska, a foldery są odtwarzane wirtualnie na podstawie ukośników w nazwach plików. Dodatkowo obiekty w ramach magazynu nie są edytowalne fragmentami, a mogą być jedynie nadpisywane w całości, co pozwala na ich automatyczne wersjonowanie.

W aplikacji \definicja{Moje Konie} usługa magazynu obiektowego jest wykorzystywana do przechowywania zdjęć koni i udostępniania ich użytkownikom. W tym celu zaimplementowano wzorzec bezpośredniego dostępu autoryzowanego. Aby zoptymalizować wydajność i zredukować obciążenie sieciowe serwera (backendu), operacje przesyłania i pobierania plików zostały oddelegowane bezpośrednio do infrastruktury \textit{Google} z wykorzystaniem mechanizmu \textit{podpisanego odnośnika} (\english{Signed URL}). Aplikacja korzysta z biblioteki \texttt{@google-cloud/storage}, która upraszcza implementację tego procesu. Mechanizm udostępniania zasobów składa się z trzech kroków:

\begin{enumerate}
    \item \textbf{Konfiguracja tożsamości i kluczy}: Uwierzytelnianie procesu podpisywania odbywa się z użyciem pary kluczy asymetrycznych. Backend posiada klucz prywatny oraz identyfikator konta usługi (\english{Service Account}), które tworzą jego tożsamość ładowaną podczas startu aplikacji. Konto to posiada nadane uprawnienia do zarządzania zasobnikiem. Weryfikacja tych uprawnień nie następuje w momencie generowania linku przez backend, lecz jest odroczona do momentu faktycznej próby dostępu przez klienta.
    
    \item \textbf{Generowanie podpisanego żądania}: Gdy użytkownik chce wykonać operację na obiekcie, backend nie łączy się z usługą \textit{Google Cloud Storage}. Zamiast tego przygotowuje autoryzację zgodnie ze standardem \textit{GOOG4-RSA-SHA256} \cite{TODO}. Proces ten polega na zamianie parametrów planowanego żądania HTTP (metody, ścieżki do zasobu, nagłówków i czasu wygaśnięcia) w znormalizowany ciąg znaków. Następnie ciąg ten przekształcany jest w skrót \textit{SHA-256}, który zostaje zaszyfrowany kluczem prywatnym backendu. Ten zaszyfrowany skrót stanowi kryptograficzny podpis dołączany do adresu URL. Utworzony odnośnik ma ograniczony czas ważności, co minimalizuje ryzyko nieuprawnionego dostępu w przypadku jego przechwycenia.
    
    \item \textbf{Weryfikacja i transfer danych}: Klient (frontend) po otrzymaniu \textit{podpisanego odnośnika} wykonuje żądanie bezpośrednio do serwerów \textit{Google Cloud Storage}. W tym momencie infrastruktura chmury weryfikuje podpis, używając klucza publicznego przypisanego do konta usługi, oraz sprawdza ważność linku i uprawnienia. Jakakolwiek ingerencja w parametry adresu URL spowoduje niezgodność z podpisem i odrzucenie żądania. Po pomyślnej autoryzacji następuje transfer danych bezpośrednio między urządzeniem użytkownika a chmurą, z całkowitym pominięciem serwera aplikacji.
\end{enumerate}


\section{Charakterystyka wykorzystanych technologii wdrożeniowych}

Współczesne procesy wytwarzania i dostarczania oprogramowania opierają się na automatyzacji oraz standaryzacji środowisk uruchomieniowych. W celu realizacji niniejszego projektu wykorzystano zestaw narzędzi umożliwiających definicję infrastruktury w kodzie, jej automatyczną konfigurację oraz izolację procesów aplikacji. Poniżej przedstawiono charakterystykę kluczowych technologii wykorzystanych w procesie wdrożenia.

\subsection{Konteneryzacja i platforma Docker}

Konteneryzacja to metoda wirtualizacji na poziomie systemu operacyjnego, która pozwala na uruchamianie aplikacji w izolowanych przestrzeniach użytkownika, zwanych kontenerami. W przeciwieństwie do tradycyjnych maszyn wirtualnych, które wymagają emulacji całego sprzętu i uruchomienia pełnego systemu operacyjnego dla każdego systemu gościa, kontenery współdzielą jądro systemu operacyjnego gospodarza. Podejście to zmniejsza zapotrzebowanie na zasoby sprzętowe oraz przyspiesza czas uruchamiania aplikacji.

\textit{Docker} jest platformą technologiczną umożliwiającą tworzenie, wdrażanie i uruchamianie aplikacji w kontenerach. Architektura rozwiązania opiera się na kilku kluczowych pojęciach:

\begin{itemize}
    \item \textbf{Obraz} (\english{Image}) -- niezmienny szablon (artefakt) zawierający kod aplikacji, biblioteki, zależności oraz definicję środowiska uruchomieniowego. Obrazy budowane są warstwowo na podstawie pliku \texttt{Dockerfile} napisanego w języku dziedzinowym (\english{domain-specific language}). Użycie warstw pozwala na efektywne wykorzystanie pamięci masowej poprzez współdzielenie identycznych warstw między różnymi obrazami.
    \item \textbf{Kontener} (\english{Container}) -- instancja obrazu uruchomiona w czasie rzeczywistym. Jest to odizolowany proces lub grupa procesów, które posiadają własny system plików i przestrzeń sieciową, odseparowaną od reszty systemu.
    \item \textbf{Silnik} (\english{Docker Engine}) -- usługa systemowa środowiska uruchomieniowego odpowiedzialnego za budowanie i obsługę cyklu życia kontenerów.
\end{itemize}

Wykorzystanie platformy Docker w projekcie zapewnia spójność środowiska pomiędzy etapem deweloperskim, testowym i produkcyjnym, eliminując problem różnic w konfiguracji bibliotek systemowych.

\subsection{Infrastruktura jako kod}

Podejście \textit{Infrastruktura jako kod} (\english{Infrastructure as Code}, \akronim{IaC}) polega na zarządzaniu infrastrukturą informatyczną (serwerami, sieciami) za pomocą plików konfiguracyjnych, zamiast ręcznej konfiguracji poprzez interfejsy graficzne czy jednorazowe skrypty. Pozwala to na wersjonowanie infrastruktury, łatwe powielanie środowisk oraz automatyzację wdrażania. W projekcie wykorzystano dwa komplementarne narzędzia realizujące ten paradygmat: \textit{Terraform} oraz \textit{Ansible}.

\subsection{Terraform -- powoływanie infrastruktury}

\textit{Terraform} to narzędzie służące do bezpiecznego i efektywnego tworzenia, zmieniania oraz wersjonowania infrastruktury. Działa w modelu deklaratywnym, co oznacza, że użytkownik definiuje w kodzie stan docelowy infrastruktury (np. jedną maszynę wirtualną i regułę zapory sieciowej), a narzędzie samodzielnie ustala kolejność operacji niezbędnych do osiągnięcia tego stanu.

Kluczową cechą \textit{Terraform} jest wykorzystanie interfejsów programistycznych dostawców usług chmurowych w celu powoływania zasobów. Deklaracja sprzętowa może opisywać jednocześnie wielu dostawców dzięki systemowi wtyczek w jednym, spójnym, dziedzinowym języku konfiguracyjnym. \textit{Terraform} powiela informacje o aktualnym stanie infrastruktury w pliku stanu, co pozwala na śledzenie zmian, planowanie aktualizacji zasobów i zapobiega nieplanowanym rekonstrukcjom stanu od zera.

\subsection{Ansible -- zarządzanie konfiguracją}

O ile \textit{Terraform} służy głównie do powoływania zasobów (tworzenia serwerów), o tyle \textit{Ansible} jest narzędziem do zarządzania konfiguracją i automatyzacji zadań na już istniejących maszynach. Pozwala na instalację oprogramowania, edycję plików konfiguracyjnych oraz zarządzanie usługami systemowymi.

\textit{Ansible} wyróżnia się architekturą bezagentową. Oznacza to, że na zarządzanych serwerach nie jest wymagana instalacja żadnego dodatkowego oprogramowania klienckiego. Komunikacja odbywa się z wykorzystaniem standardowego protokołu SSH (w systemach Linux). Scenariusze automatyzacji, zwane \textit{playbooks}, zapisywane są w formacie YAML.

Istotną cechą \textit{Ansible} jest idempotentność operacji. Oznacza to, że wielokrotne wykonanie tego samego scenariusza konfiguracji nie spowoduje błędów ani niepożądanych zmian, jeśli system znajduje się już w oczekiwanym stanie. Gwarantuje to stabilność i przewidywalność procesu wdrożenia aplikacji.

\subsection{GitHub Actions -- automatyzacja procesów}

\textit{GitHub Actions} to platforma do ciągłej integracji i ciągłego dostarczania (\english{Continuous Integration / Continuous Delivery}, \akronim{CI/CD}), zintegrowana bezpośrednio z systemem kontroli wersji \textit{GitHub}. Umożliwia ona definiowanie przepływów pracy w formacie YAML, które są automatycznie uruchamiane w odpowiedzi na określone zdarzenia w repozytorium, takie jak wypchnięcie kodu, otwarcie zgłoszenia czy utworzenie nowego wydania.

Architektura \textit{GitHub Actions} opiera się na koncepcji wykonawców (\english{runner}) -- maszyn wirtualnych lub kontenerów, na których wykonywane są zdefiniowane zadania. W projekcie wykorzystano udostępniane przez \textit{GitHub} współdzielone maszyny z systemem operacyjnym \textit{Ubuntu}, co eliminuje konieczność utrzymywania własnej infrastruktury do budowania aplikacji. Platforma ta oferuje bogaty ekosystem gotowych akcji (\english{actions}), które można wykorzystać jako modularne bloki budulcowe do tworzenia złożonych potoków wdrażania, obejmujących kompilację kodu, testowanie, budowanie obrazów kontenerowych oraz interakcję z chmurą obliczeniową.

\section{Konteneryzacja i proces budowania}

Aby zapewnić niezawodność procesu wytwarzania oprogramowania (\english{software supply chain}) oraz bezpieczeństwo wdrożenia, w projekcie wykorzystano technologię konteneryzacji. Podejście to gwarantuje spójność środowiska uruchomieniowego niezależnie od infrastruktury docelowej. Projekt składa się z monorepozytorium (TypeScript) oraz dedykowanej usługi klasyfikatora (Python). Ze względu na oddzielną architekturę projektu klasyfikatora zaimplementowaną w języku \textit{Python} zdecydowano się na rozdzielenie repozytoriów kodu. W obu przypadkach zastosowano strategie budowania obrazów zoptymalizowane pod kątem redukcji rozmiaru artefaktów oraz powierzchni ataku.

\begin{figure}[t]
\centering\includegraphics[width=\textwidth]{figures/repozytorium-zaleznosci-budowanie.png}
\caption{Struktura repozytorium kodu, uproszczony diagram zależności oraz tworzenia paczki dystrybucyjnej}\label{rys:repozytorium-zaleznosci-budowanie}
\end{figure}

W celu uniknięcia przedostania się kodu źródłowego, narzędzi deweloperskich oraz zbędnych zależności do środowiska produkcyjnego, w całym projekcie zastosowano mechanizm wieloetapowego budowania. Konfiguracja obrazów \textit{Docker} dla monorepozytorium (frontend i backend) zdefiniowana dzieli proces na cztery logiczne etapy:

\begin{enumerate}
    \item \textbf{Etap kompilacji}: Wykorzystuje pełny obraz środowiska \textit{Node.js} -- środowiska uruchomieniowego kodu \textit{JavaScript}. W tym kroku następuje instalacja wszystkich zależności (w szczególności deweloperskich) z użyciem programu \textit{npm}, budowanie aplikacji i kompilacja kodu.
    \item \textbf{Etap przygotowania zależności backendu}: Ponownie obraz środowiska \textit{Node.js}, gdzie instalowane są wyłącznie biblioteki wymagane do działania backendu, lecz z pominięciem narzędzi deweloperskich. Redukuje to wektor ataku w finalnym obrazie (m.in. liczbę potencjalnych podatności i zagrożeń).
    \item \textbf{Etap scalania dla frontendu}: Finalny obraz ze statycznymi plikami aplikacji frontendu bazujący na uproszczonym obrazie serwera HTTP \textit{Nginx}. Obraz skonfigurowano pod aplikację jednostronicową i progresywną aplikację internetową. Wymagane przez aplikację zależności do działania po stronie klienta są zapewniane w procesie budowy z paczką dystrybucji. Oznacza to przekopiowanie zależności do paczki lub utworzenie odnośników do pobrania paczek z sieci dostarczania zawartości (\english{Content Delivery Network}, \akronim{CDN}). 
    \item \textbf{Etap scalania dla backendu}: Finalny obraz uruchamiający serwer backendu rozszerzający uproszczony obraz środowiska \textit{Node.js} o skompilowany kod z pierwszej i pliki zależności z drugiej warstwy.
\end{enumerate}

W procesie wykorzystano nowoczesny mechanizm buforowania (\english{cache}) dostępny w silniku budowania \textit{Docker BuildKit}. Pozwala on na przechowywanie pobranych pakietów menedżera zależności pomiędzy kolejnymi uruchomieniami potoku przetwarzania, co redukuje ruch sieciowy i przyspiesza proces.

Moduł klasyfikatora intencji, napisany w języku Python, wymagał odrębnego podejścia do procesu budowania. Ze względu na specyfikę środowiska Python oraz konieczność obsługi dużych bibliotek numerycznych i uczenia maszynowego (takich jak \textit{scikit-learn}, \textit{sentence-transformers}, \textit{numpy}) wykorzystano menedżer pakietów \textit{uv}. Zastosowana strategia budowania obrazu \textit{Docker} opiera się na zaleceniach z dokumentacji \textit{uv} i korzysta m.in. z dedykowanego obrazu z preinstalowanym narzędziem \textit{uv} i interpreterem języka \textit{Python}, pomija zależności deweloperskie, wymusza kompilację plików źródłowych Python do kodu bajtowego (.pyc), wstępnie przetwarza i weryfikuje zbiór danych do działania modelu.

\section{Automatyzacja procesów ciągłej integracji i dostarczania}

Proces ciągłej integracji i dostarczania (\english{Continuous Integration / Continuous Delivery}, CI/CD) został w pełni zautomatyzowany z wykorzystaniem platformy \textit{GitHub Actions}. Potok przetwarzania jest uruchamiany automatycznie przy każdym wypchnięciu zmian do gałęzi głównej (\texttt{main}) lub utworzeniu tagu wersji (np. \texttt{v1.0.0}).

Kluczowym aspektem wdrożonego potoku jest jego optymalizacja pod kątem czasu wykonania oraz bezpieczeństwa łańcucha dostaw. Składa się on z następujących, sekwencyjnie wykonywanych kroków:

\begin{enumerate}
    \item \textbf{Inicjalizacja środowiska}: Konfiguracja narzędzia \textit{Cosign} (do podpisywania obrazów \textit{Docker}) oraz \textit{Docker Buildx} (silnika budowania obrazów \textit{Docker} obsługującego zaawansowany mechanizm buforowania pakietów).
    \item \textbf{Uwierzytelnienie}: Logowanie do rejestru obrazów \textit{Docker} -- \textit{GitHub Container Registry} przy użyciu jednorazowego tokenu generowanego przez GitHub dla czasu trwania zadania.
    \item \textbf{Zarządzanie pamięcią podręczną}: W celu przyspieszenia instalacji zależności w kontenerach, zastosowano technikę \textit{cache dance}. Pozwala ona na wstrzyknięcie pamięci podręcznej z systemu plików \textit{GitHub Actions} bezpośrednio do warstw budowania \textit{Docker BuildKit}. Dzięki temu, jeśli pliki definiujące zależności (np. \texttt{package-lock.json}) nie uległy zmianie, Docker nie musi ponownie pakietów z internetu, lecz korzysta z lokalnej kopii.
    \item \textbf{Równoległe budowanie (Docker Bake)}: Zamiast sekwencyjnego budowania poszczególnych obrazów, wykorzystano moduł silinka \textit{Docker Buildx} -- \textit{Docker Bake}. Pozwala on na zdefiniowanie grup celów (backend, frontend) i ich równoległe budowanie, co skraca całkowity czas operacji. Akcja automatycznie zarządza tagowaniem obrazów oraz przesyłaniem ich do rejestru \textit{GitHub Container Registry}.
    \item \textbf{Kryptograficzne podpisywanie obrazów}: Każdy zbudowany i przesłany obraz \textit{Docker} jest podpisywany cyfrowo przy użyciu narzędzia \textit{Cosign} w trybie \textit{keyless}. Korzysta on z tymczasowej tożsamości (aktywnej tylko w trakcie działania potoku i dostępnej tylko wewnątrz środowiska GitHub Actions) do wygenerowania ulotnego certyfikatu do podpisu. Dzięki temu, w rejestrze publicznym (\textit{Rekor transparency log}) odkładany jest dowód, że dany obraz (identyfikowany przez skrót \textit{SHA}) został zbudowany na podstawie precyzyjnej wersji kodu źródłowego w jawnie zdefiniowanym środowisku \textit{Github Actions}, co zabezpiecza przed atakami typu \textit{Supply Chain}.
\end{enumerate}

\begin{figure}[t]
\centering\includegraphics[width=\textwidth]{figures/diagram-wdrozenia.png}
\caption{Diagram wdrożenia z użyciem Terraform i Ansible}\label{rys:diagram-wdrozenia}
\end{figure}

Cała infrastruktura, poza warstwą aplikacji, jest definiowana w kodzie (\english{Infrastructure as Code}, IaC) z wykorzystaniem narzędzi Terraform (do powoływania zasobów chmurowych) oraz Ansible (do konfiguracji serwera), co przedstawiono na Rysunku \ref{rys:diagram-wdrozenia}.

Proces wdrażania zmian w infrastrukturze i aplikacji podzielony jest na trzy uzupełniające się warstwy:

\begin{enumerate}
    \item \textbf{Infrastruktura chmurowa (Terraform)}: Warstwa ta definiuje zasoby w chmurze \textit{Google Cloud Platform}. Skrypty \textit{Terraform} uruchamiane z lokalnej maszyny deweloperskiej odpowiadają za powołanie instancji maszyny wirtualnej i zewnętrznych partycji dysków trwałych, rezerwację statycznych adresów IP, konfigurację zapory sieciowej, otwierając jedynie niezbędne porty dla ruchu przychodzącego i zasobników magazynu obiektowego do zdjęć wraz z regułami dostępu oraz kontem usługi.
    
    \item \textbf{Konfiguracja systemu operacyjnego (Ansible)}: Po powołaniu infrastruktury, narzędzie \textit{Ansible} jest wykorzystywane do wstępnej konfiguracji serwera. Skrypty te, również uruchamiane doraźnie (podczas pierwszej konfiguracji systemu), instalują środowisko uruchomieniowe \textit{Docker}, konfigurują zewnętrzne dyski trwałe (dedykowane osobno dla danych bazy danych i osobno dla kopii zapasowych w celu zapewnienia odpowiedniej wydajności i separacji awarii) oraz konfigurują narzędzie \textit{Borgmatic} do automatycznego tworzenia szyfrowanych kopii zapasowych bazy danych (działające poza środowiskiem Docker ze względu na ograniczenia tej technologii do uruchamiania zadań okresowych).
    
    \item \textbf{Wdrażanie aplikacji (Ansible w CI/CD)}: Bieżące aktualizacje kodu aplikacji są obsługiwane przez automatyczne przepływy pracy w \textit{GitHub Actions}. Przepływ pracy po wypchnięciu zmian do repozytorium kontroli wersji uruchamia zestaw zadań, który bezpiecznie kopiuje pliki konfiguracyjne \textit{Docker Compose} definiujące uruchomienie kontenerów na serwer oraz zmienne środowiskowe (takie jak hasła do bazy danych czy klucze API) pobrane z bezpiecznego magazynu sekretów \textit{GitHub Secrets} bezpośrednio do pliku \texttt{.env} na serwerze. Następnie \textit{Ansible} wykonuje polecenia restartu kontenerów, co powoduje pobranie najnowszych obrazów i uruchomienie zaktualizowanej wersji aplikacji. Proces ten jest rozdzielony na niezależne przepływy dla głównej aplikacji, klasyfikatora NLP oraz warstwy bazy danych i proxy, co pozwala na niezależne aktualizacje komponentów. Dodatkowo, wszystkie kontenery aplikacyjne, w tym klasyfikator, działają w trybie automatycznego restartu, co przywraca dostępność usług w przypadku przejściowych awarii.
\end{enumerate}

\section{Mechanizmy bezpieczeństwa}

Wdrożenie systemu zrealizowano zgodnie ze strategią obrony w głąb, implementując wielowarstwowe mechanizmy zabezpieczeń obejmujące łańcuch dostaw, infrastrukturę sieciową, środowisko uruchomieniowe oraz warstwę aplikacji.

\subsection{Bezpieczeństwo infrastruktury sieciowej}

Ochrona serwera i kontenerów opiera się na minimalizacji powierzchni ataku:

\begin{itemize}

    \item \textbf{Ochrona sieciowa (Cloudflare i Firewall)}: Punktem wejścia do systemu jest usługa \textit{Cloudflare}, pełniąca funkcję zapory sieciowej aplikacji (\english{Web Application Firewall}, \akronim{WAF}) oraz serwera nazw domen (\english{Domain Name System}, \akronim{DNS}). Ukrywa ona rzeczywisty adres IP serwera i filtruje złośliwy ruch. Zapora sieciowa \textit{Google Cloud} dodatkowo ogranicza ruch przychodzący do serwera wyłącznie do protokołów HTTPS i SSH.
    \item \textbf{Odwrotny pośrednik (Traefik)}: Bezpośrednio na serwerze ruchem zarządza odwrotne proxy (\english{reverse proxy}) \textit{Traefik}. Jest on skonfigurowany jako jedyny punkt styku udostępnionych aplikacji z siecią zewnętrzną, obsługując wyłącznie ruch szyfrowany na porcie \texttt{443} -- po protokole HTTPS. Certyfikaty TLS są zapewniane dzięki bezpłatnej usłudze zautomatyzowanego i otwartego urzędu certyfikacji \textit{Lets's Encrypt} udostępnianej przez organizację non-profit Internet Security Research Group (\akronim{ISRG}). \textit{Traefik} automatycznie zarządza cyklem życia certyfikatów TLS, wykorzystując mechanizm wyzwań DNS (\english{DNS challenge}) w integracji z API \textit{Cloudflare}. Użycie tego mechanizmu pozwala na uzyskanie zaufanych certyfikatów z usługi \textit{Let's Encrypt} bez ujawniania publicznie powiązania zewnętrznego adresu IP serwera aplikacji z nazwą domenową (wszystkie żądania certyfikatów są zapisywane w publicznym rejestrze, a inne mechanizmy wyzwań służących potwierdzeniu autentyczności żądania wymagają bezpośredniego ruchu po nazwie domenowej do serwera z Internetu).
    \item \textbf{Izolowane sieci wirtualne}:  Separacja komponentów systemu została zrealizowana poprzez izolowane sieci wirtualne wewnątrz środowiska \textit{Docker}. Kontener bazy danych PostgreSQL nie udostępnia żadnych portów na zewnątrz hosta i jest dostępny wyłącznie dla kontenera backendu poprzez dedykowaną sieć wewnętrzną. Taka konfiguracja uniemożliwia bezpośredni dostęp do danych z poziomu Internetu, nawet w przypadku błędnej konfiguracji zapory ogniowej.
\end{itemize}

\subsection{Bezpieczeństwo aplikacji i środowiska uruchomieniowego}

Na poziomie kodu aplikacji wdrożono mechanizmy zapobiegające błędom logicznym i wstrzyknięciom:

\begin{itemize}
    \item \textbf{Walidacja danych (Zod)}: Wszystkie dane wejściowe trafiające do API są rygorystycznie weryfikowane przy użyciu biblioteki \textit{Zod} pod kątem zgodności ze zdefiniowanym schematem. Zapobiega to przetwarzaniu nieprawidłowych lub złośliwych struktur danych.
    \item \textbf{Architektura modułowa}: Podział systemu na niezależne kontenery (frontend, backend, klasyfikator, baza danych) odseparowane wirtualnymi sieciami \textit{Docker} ogranicza zasięg ewentualnego ataku (\english{blast radius}). Kompromitacja jednego elementu (np. klasyfikatora) nie zapewnia dostępu do innych komponentów (np. do bazy danych, która akceptuje połączenia tylko z sieci wewnętrznej).
    \item \textbf{Dodatkowo zabezpieczone obrazy kontenerów}: Aplikacje uruchamiane są w oparciu o obrazy, takie jak \textit{Google Distroless Node.js} (dla backendu) czy \textit{Chainguard Nginx} (dla frontendu). Obrazy te są pozbawione powłoki systemowej (shell) oraz zbędnych narzędzi, co drastycznie utrudnia atakującemu wykonanie złośliwego kodu w przypadku przełamania zabezpieczeń aplikacji.
    \item \textbf{Zasada najmniejszych przywilejów}: Kontenery są skonfigurowane do pracy bez uprawnień administratora (\english{root}), wykorzystując dedykowanych użytkowników systemowych. Zapobiega to eskalacji uprawnień na system gospodarza w przypadku ucieczki z kontenera.
\end{itemize}

\subsection{Bezpieczeństwo łańcucha dostaw}

Istotnym elementem bezpieczeństwa nowoczesnych systemów jest ochrona procesu wytwarzania oprogramowania (\english{Software Supply Chain Security}). W projekcie zastosowano szereg mechanizmów gwarantujących integralność i pochodzenie kodu:

\begin{itemize}
    \item \textbf{Podpisywanie obrazów (Cosign i Rekor)}: Wszystkie obrazy \textit{Docker} generowane w procesie CI/CD są kryptograficznie podpisywane przy użyciu narzędzia \textit{Cosign} w trybie \textit{keyless}. Mechanizm ten wykorzystuje protokół \textit{OpenID Connect} (OIDC) do uwierzytelnienia tożsamości procesu \textit{GitHub Actions} w urzędzie certyfikacji \textit{Fulcio}, który wydaje krótkotrwały certyfikat cyfrowy. Podpisany skrót obrazu jest następnie rejestrowany w publicznym, niemodyfikowalnym logu transparentności \textit{Rekor}. Umożliwia to późniejszą weryfikację, że dany obraz został zbudowany z konkretnej, precyzyjnej wersji kodu źródłowego w zaufanym środowisku wykonawczym, uniemożliwiając podstawienie złośliwego artefaktu przez osoby trzecie.

    \item \textbf{Automatyzacja aktualizacji (Dependabot)}: W repozytorium skonfigurowano narzędzie \textit{Dependabot}, które okresowo monitoruje zależności projektu pod kątem znanych podatności (CVE). W przypadku wykrycia luki bezpieczeństwa w używanej bibliotece system automatycznie generuje zgłoszenie z aktualizacją do bezpiecznej wersji, co pozwala na szybką reakcję na nowe zagrożenia.

    \item \textbf{Precyzyjne wersjonowanie zależności}: Aby zagwarantować powtarzalność procesu budowania (ang. \english{reproducible builds}) i ochronę przed atakami na łańcuch dostaw, zastosowano precyzyjne wersje bibliotek. W projekcie wykorzystano pliki \texttt{package-lock.json} (dla ekosystemu \textit{Node.js}) oraz \texttt{uv.lock} (dla środowiska \textit{Python}), które zawierają sumy kontrolne konkretnych wersji pakietów. Gwarantuje to instalację identycznego kodu na każdym środowisku. Dodatkowo, w definicjach przepływów pracy \textit{GitHub Actions}, odwołania do zewnętrznych akcji realizowane są poprzez unikalny skrót SHA identyfikujący zmianę (np. \texttt{actions/checkout@a5ac7...}), zamiast modyfikowalnych tagów wersji, co eliminuje ryzyko wykonania złośliwego kodu w przypadku przejęcia repozytorium dostawcy akcji.
\end{itemize}
